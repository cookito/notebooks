{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #基本モジュール\n",
    "from torch.autograd import Variable #自動微分用\n",
    "import torch.nn as nn #ネットワーク構築用\n",
    "import torch.optim as optim #最適化関数\n",
    "import torch.nn.functional as F #ネットワーク用の様々な関数\n",
    "import torch.utils.data #データセット読み込み関連\n",
    "import torchvision #画像関連\n",
    "from torchvision import datasets, models, transforms #画像用データセット諸々\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "import logzero\n",
    "from logzero import logger\n",
    "\n",
    "\n",
    "# examination settings\n",
    "batch_size = 128\n",
    "test_batch_size = batch_size * 2\n",
    "epochs = 1000\n",
    "lr = 0.5\n",
    "momentum = 0.9\n",
    "seed = 2017\n",
    "log_interval = 1000\n",
    "num_workers = 2\n",
    "use_gpu = False\n",
    "ex_name = 'supervised'\n",
    "\n",
    "# set seed for reproducibility\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# logger setting\n",
    "LOG_FORMAT = '[%(asctime)s %(levelname)s] %(message)s'\n",
    "logzero.loglevel(logging.INFO)\n",
    "logzero.logfile('./log/{}.log'.format(ex_name))\n",
    "logzero.formatter(logging.Formatter(LOG_FORMAT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST('./data/MNIST/train/', download=True, train=True)\n",
    "test_dataset = datasets.MNIST('./data/MNIST/test/', download=True, train=False)\n",
    "\n",
    "train_data = train_dataset.train_data.numpy()\n",
    "test_data = test_dataset.test_data.numpy()\n",
    "train_labels = train_dataset.train_labels.numpy()\n",
    "test_labels = test_dataset.test_labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels), len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the ratio train/test\n",
    "train:val:test を 800:200:69000に設定。各クラスのサンプル数は均一に。testセットは実際に教師なし学習に用いることは想定しづらいので、現実のタスクや論文に書く時はunlabeledデータとして説明すれば良い。その場合はtestセット内で更に unlabeled/holdout に分ける必要がある。\n",
    "交差検証は行わない。\n",
    "\n",
    "pseudo label実験に対してはtestデータはunlabeledデータ及び最終評価用のデータとして使われる。valは学習中の精度監視用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_train = 1000\n",
    "n_val = 1000\n",
    "n_test = 68000\n",
    "\n",
    "X_train = np.empty(shape=(0, 28, 28))\n",
    "y_train = np.empty(shape=(0,))\n",
    "X_val = np.empty(shape=(0, 28, 28))\n",
    "y_val = np.empty(shape=(0,))\n",
    "X_test = np.empty(shape=(0, 28, 28))\n",
    "y_test = np.empty(shape=(0,))\n",
    "\n",
    "for i in range(10):\n",
    "    idx_train = np.argwhere(train_labels == i)[:(n_train//10)].squeeze()\n",
    "    idx_val = np.argwhere(train_labels == i)[(n_train//10):((n_train+n_val)//10)].squeeze()\n",
    "    idx_test = np.argwhere(train_labels == i)[((n_train+n_val)//10):].squeeze()\n",
    "    \n",
    "    X_train = np.concatenate([X_train, train_data[idx_train]], axis=0)\n",
    "    y_train = np.concatenate([y_train, train_labels[idx_train]], axis=0)\n",
    "    X_val = np.concatenate([X_val, train_data[idx_val]], axis=0)\n",
    "    y_val = np.concatenate([y_val, train_labels[idx_val]], axis=0)\n",
    "    X_test = np.concatenate([X_test, train_data[idx_test]], axis=0)\n",
    "    y_test = np.concatenate([y_test, train_labels[idx_test]], axis=0)\n",
    "    \n",
    "X_test = np.concatenate([X_test, test_data], axis=0)\n",
    "y_test = np.concatenate([y_test, test_labels], axis=0)\n",
    "\n",
    "# treat as image\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_val = np.expand_dims(X_val, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "\n",
    "# one-hot encoding\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_val = lb.transform(y_val)\n",
    "y_test = lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 1) (1000, 10) (1000, 28, 28, 1) (1000, 10) (68000, 28, 28, 1) (68000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.fc = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.bn1(self.conv1(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.bn2(self.conv2(x)), 2))\n",
    "        x = F.adaptive_avg_pool2d(x, output_size=1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.X[index]\n",
    "        img = self.transform(img)\n",
    "        target = torch.Tensor(self.y[index].astype(float))\n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_dataset = MNISTDataset(X_train, y_train, transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "val_dataset = MNISTDataset(X_val, y_val, transform)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=test_batch_size, num_workers=num_workers)\n",
    "test_dataset = MNISTDataset(X_test, y_test, transform)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=test_batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define TrainingTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainingTracker(object):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.history = {\n",
    "            'train_acc': [], 'train_loss': [], 'val_acc': [], 'val_loss': []\n",
    "        }\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.train_acc = 0\n",
    "        self.train_loss = 0\n",
    "        self.val_acc = 0\n",
    "        self.val_loss = 0\n",
    "        self.train_count = 0\n",
    "        self.val_count = 0\n",
    "\n",
    "    def update(self, train, acc, loss, n):\n",
    "        if train:\n",
    "            acc_sum = self.train_acc * self.train_count + acc * n\n",
    "            loss_sum = self.train_loss * self.train_count + loss * n\n",
    "            self.train_count += n\n",
    "            self.train_acc = acc_sum / self.train_count\n",
    "            self.train_loss = loss_sum / self.train_count\n",
    "        else:\n",
    "            acc_sum = self.val_acc * self.val_count + acc * n\n",
    "            loss_sum = self.val_loss * self.val_count + loss * n\n",
    "            self.val_count += n\n",
    "            self.val_acc = acc_sum / self.val_count\n",
    "            self.val_loss = loss_sum / self.val_count\n",
    "\n",
    "    def plot_history(self):\n",
    "        plt.plot(self.history['train_acc'])\n",
    "        plt.plot(self.history['val_acc'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.legend(['train_acc', 'val_acc'], loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(self.history['train_loss'])\n",
    "        plt.plot(self.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.legend(['train_loss', 'val_loss'], loc='lower right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define train, validate, test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def _train(model, data_loader, criterion, optimizer, tracker):\n",
    "    model.train()\n",
    "    for i, (X, y) in enumerate(data_loader):\n",
    "        if use_gpu:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        X, y = Variable(X), Variable(y)\n",
    "        \n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        pred = output.data.max(1)[1]\n",
    "        answer = y.data.max(1)[1]\n",
    "        acc = pred.eq(answer).sum() / len(X)\n",
    "        tracker.update(train=True, acc=acc, loss=loss.data[0], n=len(X))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    logger.info(\n",
    "        'Epoch: {tracker.epoch} | '\n",
    "        'TrainAcc: {tracker.train_acc:.4f} | '\n",
    "        'TrainLoss: {tracker.train_loss:.4f}'.format(\n",
    "            tracker=tracker)\n",
    "    )\n",
    "    tracker.history['train_acc'].append(tracker.train_acc)\n",
    "    tracker.history['train_loss'] .append(tracker.train_loss)\n",
    "    tracker.reset()\n",
    "\n",
    "def _validate(model, data_loader, criterion, tracker):\n",
    "    model.eval()\n",
    "    for i, (X, y) in enumerate(data_loader):\n",
    "        if use_gpu:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        X, y = Variable(X), Variable(y)\n",
    "        \n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        pred = output.data.max(1)[1]\n",
    "        answer = y.data.max(1)[1]\n",
    "        acc = pred.eq(answer).sum() / len(X)\n",
    "        tracker.update(train=False, acc=acc, loss=loss.data[0], n=len(X))\n",
    "\n",
    "    logger.info(\n",
    "        'Epoch: {tracker.epoch} | '\n",
    "        'ValAcc: {tracker.val_acc:.4f} | '\n",
    "        'ValLoss: {tracker.val_loss:.4f} \\n'.format(\n",
    "            tracker=tracker)\n",
    "    )\n",
    "    tracker.history['val_acc'].append(tracker.val_acc)\n",
    "    tracker.history['val_loss'].append(tracker.val_loss)\n",
    "    tracker.reset()\n",
    "    \n",
    "def _test(model, data_loader, criterion, make_pl=False):\n",
    "    model.eval()\n",
    "    \n",
    "    if make_pl:\n",
    "        pseudo_label = np.empty((0, 10))\n",
    "    \n",
    "    acc_sum = 0\n",
    "    loss_sum = 0\n",
    "    for i, (X, y) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        if use_gpu:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        X, y = Variable(X), Variable(y)\n",
    "        \n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        pred = output.data.max(1)[1]\n",
    "        answer = y.data.max(1)[1]\n",
    "        acc_sum += pred.eq(answer).sum()\n",
    "        loss_sum += loss.data[0] * X.size(0)\n",
    "        \n",
    "        if make_pl:\n",
    "            pseudo_label = np.concatenate([pseudo_label, output.data.numpy()], axis=0)\n",
    "\n",
    "    acc = acc_sum / n_test\n",
    "    loss = loss_sum / n_test\n",
    "    logger.info(\n",
    "        'TestAcc: {0:.4f} |'\n",
    "        'TestLoss: {1:.4f} '.format(\n",
    "            acc, loss)\n",
    "    )\n",
    "    \n",
    "    if make_pl:\n",
    "        np.save('./save/pseudo_label.npy', pseudo_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:08:22,959 INFO] Epoch: 0 | TrainAcc: 0.1040 | TrainLoss: 0.2303\n",
      "[2017-12-02 05:08:23,282 INFO] Epoch: 0 | ValAcc: 0.1400 | ValLoss: 0.2300 \n",
      "\n",
      "[2017-12-02 05:08:23,915 INFO] Epoch: 1 | TrainAcc: 0.1640 | TrainLoss: 0.2267\n",
      "[2017-12-02 05:08:24,218 INFO] Epoch: 1 | ValAcc: 0.1320 | ValLoss: 0.2282 \n",
      "\n",
      "[2017-12-02 05:08:24,868 INFO] Epoch: 2 | TrainAcc: 0.2400 | TrainLoss: 0.2234\n",
      "[2017-12-02 05:08:25,173 INFO] Epoch: 2 | ValAcc: 0.2360 | ValLoss: 0.2242 \n",
      "\n",
      "[2017-12-02 05:08:25,892 INFO] Epoch: 3 | TrainAcc: 0.3260 | TrainLoss: 0.2190\n",
      "[2017-12-02 05:08:26,222 INFO] Epoch: 3 | ValAcc: 0.3310 | ValLoss: 0.2188 \n",
      "\n",
      "[2017-12-02 05:08:26,897 INFO] Epoch: 4 | TrainAcc: 0.3710 | TrainLoss: 0.2132\n",
      "[2017-12-02 05:08:27,214 INFO] Epoch: 4 | ValAcc: 0.3200 | ValLoss: 0.2125 \n",
      "\n",
      "[2017-12-02 05:08:27,879 INFO] Epoch: 5 | TrainAcc: 0.3230 | TrainLoss: 0.2061\n",
      "[2017-12-02 05:08:28,186 INFO] Epoch: 5 | ValAcc: 0.3030 | ValLoss: 0.2038 \n",
      "\n",
      "[2017-12-02 05:08:28,920 INFO] Epoch: 6 | TrainAcc: 0.3670 | TrainLoss: 0.1978\n",
      "[2017-12-02 05:08:29,226 INFO] Epoch: 6 | ValAcc: 0.2660 | ValLoss: 0.1976 \n",
      "\n",
      "[2017-12-02 05:08:29,965 INFO] Epoch: 7 | TrainAcc: 0.4120 | TrainLoss: 0.1884\n",
      "[2017-12-02 05:08:30,286 INFO] Epoch: 7 | ValAcc: 0.2680 | ValLoss: 0.1962 \n",
      "\n",
      "[2017-12-02 05:08:30,915 INFO] Epoch: 8 | TrainAcc: 0.4000 | TrainLoss: 0.1795\n",
      "[2017-12-02 05:08:31,213 INFO] Epoch: 8 | ValAcc: 0.2160 | ValLoss: 0.2043 \n",
      "\n",
      "[2017-12-02 05:08:31,954 INFO] Epoch: 9 | TrainAcc: 0.4610 | TrainLoss: 0.1704\n",
      "[2017-12-02 05:08:32,462 INFO] Epoch: 9 | ValAcc: 0.3250 | ValLoss: 0.1846 \n",
      "\n",
      "[2017-12-02 05:08:33,412 INFO] Epoch: 10 | TrainAcc: 0.4650 | TrainLoss: 0.1629\n",
      "[2017-12-02 05:08:33,720 INFO] Epoch: 10 | ValAcc: 0.3040 | ValLoss: 0.1884 \n",
      "\n",
      "[2017-12-02 05:08:34,400 INFO] Epoch: 11 | TrainAcc: 0.4980 | TrainLoss: 0.1558\n",
      "[2017-12-02 05:08:34,754 INFO] Epoch: 11 | ValAcc: 0.3970 | ValLoss: 0.1609 \n",
      "\n",
      "[2017-12-02 05:08:35,396 INFO] Epoch: 12 | TrainAcc: 0.5070 | TrainLoss: 0.1500\n",
      "[2017-12-02 05:08:35,699 INFO] Epoch: 12 | ValAcc: 0.3400 | ValLoss: 0.1672 \n",
      "\n",
      "[2017-12-02 05:08:36,344 INFO] Epoch: 13 | TrainAcc: 0.5440 | TrainLoss: 0.1439\n",
      "[2017-12-02 05:08:36,660 INFO] Epoch: 13 | ValAcc: 0.4920 | ValLoss: 0.1510 \n",
      "\n",
      "[2017-12-02 05:08:37,330 INFO] Epoch: 14 | TrainAcc: 0.5680 | TrainLoss: 0.1378\n",
      "[2017-12-02 05:08:37,650 INFO] Epoch: 14 | ValAcc: 0.2410 | ValLoss: 0.2037 \n",
      "\n",
      "[2017-12-02 05:08:38,294 INFO] Epoch: 15 | TrainAcc: 0.5930 | TrainLoss: 0.1332\n",
      "[2017-12-02 05:08:38,668 INFO] Epoch: 15 | ValAcc: 0.1690 | ValLoss: 0.2235 \n",
      "\n",
      "[2017-12-02 05:08:39,372 INFO] Epoch: 16 | TrainAcc: 0.6130 | TrainLoss: 0.1277\n",
      "[2017-12-02 05:08:39,740 INFO] Epoch: 16 | ValAcc: 0.4830 | ValLoss: 0.1422 \n",
      "\n",
      "[2017-12-02 05:08:40,476 INFO] Epoch: 17 | TrainAcc: 0.6060 | TrainLoss: 0.1222\n",
      "[2017-12-02 05:08:40,782 INFO] Epoch: 17 | ValAcc: 0.4850 | ValLoss: 0.1395 \n",
      "\n",
      "[2017-12-02 05:08:41,410 INFO] Epoch: 18 | TrainAcc: 0.6410 | TrainLoss: 0.1168\n",
      "[2017-12-02 05:08:41,722 INFO] Epoch: 18 | ValAcc: 0.4590 | ValLoss: 0.1502 \n",
      "\n",
      "[2017-12-02 05:08:42,497 INFO] Epoch: 19 | TrainAcc: 0.6620 | TrainLoss: 0.1131\n",
      "[2017-12-02 05:08:42,875 INFO] Epoch: 19 | ValAcc: 0.4560 | ValLoss: 0.1418 \n",
      "\n",
      "[2017-12-02 05:08:43,519 INFO] Epoch: 20 | TrainAcc: 0.6540 | TrainLoss: 0.1094\n",
      "[2017-12-02 05:08:43,822 INFO] Epoch: 20 | ValAcc: 0.4780 | ValLoss: 0.1355 \n",
      "\n",
      "[2017-12-02 05:08:44,539 INFO] Epoch: 21 | TrainAcc: 0.6670 | TrainLoss: 0.1046\n",
      "[2017-12-02 05:08:44,855 INFO] Epoch: 21 | ValAcc: 0.5270 | ValLoss: 0.1242 \n",
      "\n",
      "[2017-12-02 05:08:45,570 INFO] Epoch: 22 | TrainAcc: 0.7170 | TrainLoss: 0.0998\n",
      "[2017-12-02 05:08:45,879 INFO] Epoch: 22 | ValAcc: 0.2790 | ValLoss: 0.2897 \n",
      "\n",
      "[2017-12-02 05:08:46,550 INFO] Epoch: 23 | TrainAcc: 0.7220 | TrainLoss: 0.0959\n",
      "[2017-12-02 05:08:46,866 INFO] Epoch: 23 | ValAcc: 0.2730 | ValLoss: 0.2332 \n",
      "\n",
      "[2017-12-02 05:08:47,560 INFO] Epoch: 24 | TrainAcc: 0.7310 | TrainLoss: 0.0937\n",
      "[2017-12-02 05:08:47,905 INFO] Epoch: 24 | ValAcc: 0.3570 | ValLoss: 0.1655 \n",
      "\n",
      "[2017-12-02 05:08:48,579 INFO] Epoch: 25 | TrainAcc: 0.7480 | TrainLoss: 0.0909\n",
      "[2017-12-02 05:08:48,919 INFO] Epoch: 25 | ValAcc: 0.4560 | ValLoss: 0.1658 \n",
      "\n",
      "[2017-12-02 05:08:49,594 INFO] Epoch: 26 | TrainAcc: 0.7770 | TrainLoss: 0.0822\n",
      "[2017-12-02 05:08:49,996 INFO] Epoch: 26 | ValAcc: 0.4740 | ValLoss: 0.1582 \n",
      "\n",
      "[2017-12-02 05:08:50,680 INFO] Epoch: 27 | TrainAcc: 0.7810 | TrainLoss: 0.0787\n",
      "[2017-12-02 05:08:51,002 INFO] Epoch: 27 | ValAcc: 0.2560 | ValLoss: 0.2454 \n",
      "\n",
      "[2017-12-02 05:08:51,687 INFO] Epoch: 28 | TrainAcc: 0.7920 | TrainLoss: 0.0752\n",
      "[2017-12-02 05:08:52,011 INFO] Epoch: 28 | ValAcc: 0.3660 | ValLoss: 0.2020 \n",
      "\n",
      "[2017-12-02 05:08:52,660 INFO] Epoch: 29 | TrainAcc: 0.8050 | TrainLoss: 0.0723\n",
      "[2017-12-02 05:08:53,036 INFO] Epoch: 29 | ValAcc: 0.2480 | ValLoss: 0.3574 \n",
      "\n",
      "[2017-12-02 05:08:53,751 INFO] Epoch: 30 | TrainAcc: 0.8170 | TrainLoss: 0.0689\n",
      "[2017-12-02 05:08:54,093 INFO] Epoch: 30 | ValAcc: 0.4210 | ValLoss: 0.1587 \n",
      "\n",
      "[2017-12-02 05:08:54,823 INFO] Epoch: 31 | TrainAcc: 0.8290 | TrainLoss: 0.0665\n",
      "[2017-12-02 05:08:55,134 INFO] Epoch: 31 | ValAcc: 0.5280 | ValLoss: 0.1186 \n",
      "\n",
      "[2017-12-02 05:08:55,832 INFO] Epoch: 32 | TrainAcc: 0.8510 | TrainLoss: 0.0617\n",
      "[2017-12-02 05:08:56,179 INFO] Epoch: 32 | ValAcc: 0.3280 | ValLoss: 0.1864 \n",
      "\n",
      "[2017-12-02 05:08:56,812 INFO] Epoch: 33 | TrainAcc: 0.8350 | TrainLoss: 0.0607\n",
      "[2017-12-02 05:08:57,100 INFO] Epoch: 33 | ValAcc: 0.4830 | ValLoss: 0.1568 \n",
      "\n",
      "[2017-12-02 05:08:57,724 INFO] Epoch: 34 | TrainAcc: 0.8490 | TrainLoss: 0.0572\n",
      "[2017-12-02 05:08:58,026 INFO] Epoch: 34 | ValAcc: 0.7370 | ValLoss: 0.0800 \n",
      "\n",
      "[2017-12-02 05:08:58,652 INFO] Epoch: 35 | TrainAcc: 0.8790 | TrainLoss: 0.0527\n",
      "[2017-12-02 05:08:58,946 INFO] Epoch: 35 | ValAcc: 0.1970 | ValLoss: 0.4657 \n",
      "\n",
      "[2017-12-02 05:08:59,569 INFO] Epoch: 36 | TrainAcc: 0.8810 | TrainLoss: 0.0511\n",
      "[2017-12-02 05:08:59,866 INFO] Epoch: 36 | ValAcc: 0.5630 | ValLoss: 0.1303 \n",
      "\n",
      "[2017-12-02 05:09:00,495 INFO] Epoch: 37 | TrainAcc: 0.8740 | TrainLoss: 0.0506\n",
      "[2017-12-02 05:09:00,798 INFO] Epoch: 37 | ValAcc: 0.3810 | ValLoss: 0.2284 \n",
      "\n",
      "[2017-12-02 05:09:01,427 INFO] Epoch: 38 | TrainAcc: 0.8780 | TrainLoss: 0.0495\n",
      "[2017-12-02 05:09:01,720 INFO] Epoch: 38 | ValAcc: 0.6710 | ValLoss: 0.0947 \n",
      "\n",
      "[2017-12-02 05:09:02,355 INFO] Epoch: 39 | TrainAcc: 0.8770 | TrainLoss: 0.0474\n",
      "[2017-12-02 05:09:02,650 INFO] Epoch: 39 | ValAcc: 0.4670 | ValLoss: 0.2089 \n",
      "\n",
      "[2017-12-02 05:09:03,275 INFO] Epoch: 40 | TrainAcc: 0.8830 | TrainLoss: 0.0451\n",
      "[2017-12-02 05:09:03,567 INFO] Epoch: 40 | ValAcc: 0.4810 | ValLoss: 0.1392 \n",
      "\n",
      "[2017-12-02 05:09:04,203 INFO] Epoch: 41 | TrainAcc: 0.8720 | TrainLoss: 0.0452\n",
      "[2017-12-02 05:09:04,498 INFO] Epoch: 41 | ValAcc: 0.5120 | ValLoss: 0.1412 \n",
      "\n",
      "[2017-12-02 05:09:05,136 INFO] Epoch: 42 | TrainAcc: 0.9120 | TrainLoss: 0.0407\n",
      "[2017-12-02 05:09:05,440 INFO] Epoch: 42 | ValAcc: 0.7030 | ValLoss: 0.0806 \n",
      "\n",
      "[2017-12-02 05:09:06,079 INFO] Epoch: 43 | TrainAcc: 0.9060 | TrainLoss: 0.0389\n",
      "[2017-12-02 05:09:06,376 INFO] Epoch: 43 | ValAcc: 0.4870 | ValLoss: 0.1864 \n",
      "\n",
      "[2017-12-02 05:09:07,012 INFO] Epoch: 44 | TrainAcc: 0.9240 | TrainLoss: 0.0358\n",
      "[2017-12-02 05:09:07,307 INFO] Epoch: 44 | ValAcc: 0.5060 | ValLoss: 0.1606 \n",
      "\n",
      "[2017-12-02 05:09:07,926 INFO] Epoch: 45 | TrainAcc: 0.9140 | TrainLoss: 0.0369\n",
      "[2017-12-02 05:09:08,222 INFO] Epoch: 45 | ValAcc: 0.5470 | ValLoss: 0.1388 \n",
      "\n",
      "[2017-12-02 05:09:08,848 INFO] Epoch: 46 | TrainAcc: 0.9230 | TrainLoss: 0.0337\n",
      "[2017-12-02 05:09:09,138 INFO] Epoch: 46 | ValAcc: 0.6090 | ValLoss: 0.1179 \n",
      "\n",
      "[2017-12-02 05:09:09,815 INFO] Epoch: 47 | TrainAcc: 0.9340 | TrainLoss: 0.0313\n",
      "[2017-12-02 05:09:10,127 INFO] Epoch: 47 | ValAcc: 0.3270 | ValLoss: 0.4180 \n",
      "\n",
      "[2017-12-02 05:09:10,752 INFO] Epoch: 48 | TrainAcc: 0.9270 | TrainLoss: 0.0325\n",
      "[2017-12-02 05:09:11,048 INFO] Epoch: 48 | ValAcc: 0.5740 | ValLoss: 0.1341 \n",
      "\n",
      "[2017-12-02 05:09:11,684 INFO] Epoch: 49 | TrainAcc: 0.9280 | TrainLoss: 0.0321\n",
      "[2017-12-02 05:09:11,970 INFO] Epoch: 49 | ValAcc: 0.3960 | ValLoss: 0.2486 \n",
      "\n",
      "[2017-12-02 05:09:12,585 INFO] Epoch: 50 | TrainAcc: 0.9250 | TrainLoss: 0.0315\n",
      "[2017-12-02 05:09:12,879 INFO] Epoch: 50 | ValAcc: 0.6140 | ValLoss: 0.1267 \n",
      "\n",
      "[2017-12-02 05:09:13,493 INFO] Epoch: 51 | TrainAcc: 0.9410 | TrainLoss: 0.0283\n",
      "[2017-12-02 05:09:13,788 INFO] Epoch: 51 | ValAcc: 0.3180 | ValLoss: 0.3075 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:09:14,422 INFO] Epoch: 52 | TrainAcc: 0.9550 | TrainLoss: 0.0253\n",
      "[2017-12-02 05:09:14,772 INFO] Epoch: 52 | ValAcc: 0.7910 | ValLoss: 0.0634 \n",
      "\n",
      "[2017-12-02 05:09:15,508 INFO] Epoch: 53 | TrainAcc: 0.9490 | TrainLoss: 0.0244\n",
      "[2017-12-02 05:09:15,819 INFO] Epoch: 53 | ValAcc: 0.6840 | ValLoss: 0.0895 \n",
      "\n",
      "[2017-12-02 05:09:16,487 INFO] Epoch: 54 | TrainAcc: 0.9560 | TrainLoss: 0.0239\n",
      "[2017-12-02 05:09:16,817 INFO] Epoch: 54 | ValAcc: 0.6080 | ValLoss: 0.1142 \n",
      "\n",
      "[2017-12-02 05:09:17,492 INFO] Epoch: 55 | TrainAcc: 0.9580 | TrainLoss: 0.0218\n",
      "[2017-12-02 05:09:17,804 INFO] Epoch: 55 | ValAcc: 0.6060 | ValLoss: 0.1199 \n",
      "\n",
      "[2017-12-02 05:09:18,445 INFO] Epoch: 56 | TrainAcc: 0.9630 | TrainLoss: 0.0210\n",
      "[2017-12-02 05:09:18,758 INFO] Epoch: 56 | ValAcc: 0.7230 | ValLoss: 0.0836 \n",
      "\n",
      "[2017-12-02 05:09:19,468 INFO] Epoch: 57 | TrainAcc: 0.9670 | TrainLoss: 0.0215\n",
      "[2017-12-02 05:09:19,793 INFO] Epoch: 57 | ValAcc: 0.7860 | ValLoss: 0.0692 \n",
      "\n",
      "[2017-12-02 05:09:20,465 INFO] Epoch: 58 | TrainAcc: 0.9590 | TrainLoss: 0.0215\n",
      "[2017-12-02 05:09:20,783 INFO] Epoch: 58 | ValAcc: 0.7180 | ValLoss: 0.0802 \n",
      "\n",
      "[2017-12-02 05:09:21,430 INFO] Epoch: 59 | TrainAcc: 0.9510 | TrainLoss: 0.0216\n",
      "[2017-12-02 05:09:21,742 INFO] Epoch: 59 | ValAcc: 0.6560 | ValLoss: 0.1097 \n",
      "\n",
      "[2017-12-02 05:09:22,424 INFO] Epoch: 60 | TrainAcc: 0.9590 | TrainLoss: 0.0207\n",
      "[2017-12-02 05:09:22,755 INFO] Epoch: 60 | ValAcc: 0.6650 | ValLoss: 0.1071 \n",
      "\n",
      "[2017-12-02 05:09:23,412 INFO] Epoch: 61 | TrainAcc: 0.9680 | TrainLoss: 0.0187\n",
      "[2017-12-02 05:09:23,729 INFO] Epoch: 61 | ValAcc: 0.5630 | ValLoss: 0.1463 \n",
      "\n",
      "[2017-12-02 05:09:24,403 INFO] Epoch: 62 | TrainAcc: 0.9730 | TrainLoss: 0.0190\n",
      "[2017-12-02 05:09:24,726 INFO] Epoch: 62 | ValAcc: 0.6540 | ValLoss: 0.0947 \n",
      "\n",
      "[2017-12-02 05:09:25,400 INFO] Epoch: 63 | TrainAcc: 0.9600 | TrainLoss: 0.0191\n",
      "[2017-12-02 05:09:25,721 INFO] Epoch: 63 | ValAcc: 0.6150 | ValLoss: 0.1203 \n",
      "\n",
      "[2017-12-02 05:09:26,383 INFO] Epoch: 64 | TrainAcc: 0.9620 | TrainLoss: 0.0196\n",
      "[2017-12-02 05:09:26,733 INFO] Epoch: 64 | ValAcc: 0.4600 | ValLoss: 0.2282 \n",
      "\n",
      "[2017-12-02 05:09:27,389 INFO] Epoch: 65 | TrainAcc: 0.9660 | TrainLoss: 0.0193\n",
      "[2017-12-02 05:09:27,714 INFO] Epoch: 65 | ValAcc: 0.7610 | ValLoss: 0.0715 \n",
      "\n",
      "[2017-12-02 05:09:28,380 INFO] Epoch: 66 | TrainAcc: 0.9690 | TrainLoss: 0.0170\n",
      "[2017-12-02 05:09:28,707 INFO] Epoch: 66 | ValAcc: 0.6430 | ValLoss: 0.1064 \n",
      "\n",
      "[2017-12-02 05:09:29,380 INFO] Epoch: 67 | TrainAcc: 0.9810 | TrainLoss: 0.0161\n",
      "[2017-12-02 05:09:29,693 INFO] Epoch: 67 | ValAcc: 0.5440 | ValLoss: 0.1327 \n",
      "\n",
      "[2017-12-02 05:09:30,417 INFO] Epoch: 68 | TrainAcc: 0.9720 | TrainLoss: 0.0159\n",
      "[2017-12-02 05:09:30,775 INFO] Epoch: 68 | ValAcc: 0.5180 | ValLoss: 0.1397 \n",
      "\n",
      "[2017-12-02 05:09:31,445 INFO] Epoch: 69 | TrainAcc: 0.9700 | TrainLoss: 0.0159\n",
      "[2017-12-02 05:09:31,778 INFO] Epoch: 69 | ValAcc: 0.6770 | ValLoss: 0.1008 \n",
      "\n",
      "[2017-12-02 05:09:32,426 INFO] Epoch: 70 | TrainAcc: 0.9800 | TrainLoss: 0.0146\n",
      "[2017-12-02 05:09:32,732 INFO] Epoch: 70 | ValAcc: 0.7450 | ValLoss: 0.0864 \n",
      "\n",
      "[2017-12-02 05:09:33,397 INFO] Epoch: 71 | TrainAcc: 0.9810 | TrainLoss: 0.0136\n",
      "[2017-12-02 05:09:33,738 INFO] Epoch: 71 | ValAcc: 0.7910 | ValLoss: 0.0621 \n",
      "\n",
      "[2017-12-02 05:09:34,419 INFO] Epoch: 72 | TrainAcc: 0.9820 | TrainLoss: 0.0118\n",
      "[2017-12-02 05:09:34,779 INFO] Epoch: 72 | ValAcc: 0.8340 | ValLoss: 0.0542 \n",
      "\n",
      "[2017-12-02 05:09:35,458 INFO] Epoch: 73 | TrainAcc: 0.9850 | TrainLoss: 0.0119\n",
      "[2017-12-02 05:09:35,782 INFO] Epoch: 73 | ValAcc: 0.7050 | ValLoss: 0.0800 \n",
      "\n",
      "[2017-12-02 05:09:36,467 INFO] Epoch: 74 | TrainAcc: 0.9830 | TrainLoss: 0.0125\n",
      "[2017-12-02 05:09:36,778 INFO] Epoch: 74 | ValAcc: 0.6960 | ValLoss: 0.0985 \n",
      "\n",
      "[2017-12-02 05:09:37,442 INFO] Epoch: 75 | TrainAcc: 0.9910 | TrainLoss: 0.0113\n",
      "[2017-12-02 05:09:37,765 INFO] Epoch: 75 | ValAcc: 0.6550 | ValLoss: 0.0969 \n",
      "\n",
      "[2017-12-02 05:09:38,404 INFO] Epoch: 76 | TrainAcc: 0.9930 | TrainLoss: 0.0093\n",
      "[2017-12-02 05:09:38,724 INFO] Epoch: 76 | ValAcc: 0.8030 | ValLoss: 0.0565 \n",
      "\n",
      "[2017-12-02 05:09:39,396 INFO] Epoch: 77 | TrainAcc: 0.9920 | TrainLoss: 0.0092\n",
      "[2017-12-02 05:09:39,727 INFO] Epoch: 77 | ValAcc: 0.7710 | ValLoss: 0.0681 \n",
      "\n",
      "[2017-12-02 05:09:40,402 INFO] Epoch: 78 | TrainAcc: 0.9940 | TrainLoss: 0.0088\n",
      "[2017-12-02 05:09:40,738 INFO] Epoch: 78 | ValAcc: 0.8450 | ValLoss: 0.0454 \n",
      "\n",
      "[2017-12-02 05:09:41,418 INFO] Epoch: 79 | TrainAcc: 0.9940 | TrainLoss: 0.0087\n",
      "[2017-12-02 05:09:41,731 INFO] Epoch: 79 | ValAcc: 0.7760 | ValLoss: 0.0708 \n",
      "\n",
      "[2017-12-02 05:09:42,387 INFO] Epoch: 80 | TrainAcc: 0.9930 | TrainLoss: 0.0094\n",
      "[2017-12-02 05:09:42,735 INFO] Epoch: 80 | ValAcc: 0.7300 | ValLoss: 0.0829 \n",
      "\n",
      "[2017-12-02 05:09:43,387 INFO] Epoch: 81 | TrainAcc: 0.9900 | TrainLoss: 0.0095\n",
      "[2017-12-02 05:09:43,723 INFO] Epoch: 81 | ValAcc: 0.5540 | ValLoss: 0.1413 \n",
      "\n",
      "[2017-12-02 05:09:44,358 INFO] Epoch: 82 | TrainAcc: 0.9820 | TrainLoss: 0.0109\n",
      "[2017-12-02 05:09:44,648 INFO] Epoch: 82 | ValAcc: 0.6300 | ValLoss: 0.1040 \n",
      "\n",
      "[2017-12-02 05:09:45,260 INFO] Epoch: 83 | TrainAcc: 0.9890 | TrainLoss: 0.0102\n",
      "[2017-12-02 05:09:45,554 INFO] Epoch: 83 | ValAcc: 0.6940 | ValLoss: 0.1089 \n",
      "\n",
      "[2017-12-02 05:09:46,174 INFO] Epoch: 84 | TrainAcc: 0.9950 | TrainLoss: 0.0085\n",
      "[2017-12-02 05:09:46,464 INFO] Epoch: 84 | ValAcc: 0.7420 | ValLoss: 0.0890 \n",
      "\n",
      "[2017-12-02 05:09:47,070 INFO] Epoch: 85 | TrainAcc: 0.9950 | TrainLoss: 0.0075\n",
      "[2017-12-02 05:09:47,363 INFO] Epoch: 85 | ValAcc: 0.5720 | ValLoss: 0.1615 \n",
      "\n",
      "[2017-12-02 05:09:47,962 INFO] Epoch: 86 | TrainAcc: 0.9970 | TrainLoss: 0.0071\n",
      "[2017-12-02 05:09:48,258 INFO] Epoch: 86 | ValAcc: 0.7620 | ValLoss: 0.0772 \n",
      "\n",
      "[2017-12-02 05:09:48,880 INFO] Epoch: 87 | TrainAcc: 0.9970 | TrainLoss: 0.0071\n",
      "[2017-12-02 05:09:49,193 INFO] Epoch: 87 | ValAcc: 0.2800 | ValLoss: 0.3544 \n",
      "\n",
      "[2017-12-02 05:09:49,821 INFO] Epoch: 88 | TrainAcc: 0.9960 | TrainLoss: 0.0073\n",
      "[2017-12-02 05:09:50,118 INFO] Epoch: 88 | ValAcc: 0.8430 | ValLoss: 0.0494 \n",
      "\n",
      "[2017-12-02 05:09:50,759 INFO] Epoch: 89 | TrainAcc: 0.9960 | TrainLoss: 0.0070\n",
      "[2017-12-02 05:09:51,057 INFO] Epoch: 89 | ValAcc: 0.8360 | ValLoss: 0.0549 \n",
      "\n",
      "[2017-12-02 05:09:51,698 INFO] Epoch: 90 | TrainAcc: 0.9970 | TrainLoss: 0.0065\n",
      "[2017-12-02 05:09:51,994 INFO] Epoch: 90 | ValAcc: 0.8390 | ValLoss: 0.0472 \n",
      "\n",
      "[2017-12-02 05:09:52,618 INFO] Epoch: 91 | TrainAcc: 0.9960 | TrainLoss: 0.0067\n",
      "[2017-12-02 05:09:52,927 INFO] Epoch: 91 | ValAcc: 0.8110 | ValLoss: 0.0580 \n",
      "\n",
      "[2017-12-02 05:09:53,541 INFO] Epoch: 92 | TrainAcc: 0.9930 | TrainLoss: 0.0068\n",
      "[2017-12-02 05:09:53,839 INFO] Epoch: 92 | ValAcc: 0.8160 | ValLoss: 0.0542 \n",
      "\n",
      "[2017-12-02 05:09:54,484 INFO] Epoch: 93 | TrainAcc: 0.9980 | TrainLoss: 0.0059\n",
      "[2017-12-02 05:09:54,793 INFO] Epoch: 93 | ValAcc: 0.7150 | ValLoss: 0.0980 \n",
      "\n",
      "[2017-12-02 05:09:55,417 INFO] Epoch: 94 | TrainAcc: 0.9980 | TrainLoss: 0.0063\n",
      "[2017-12-02 05:09:55,725 INFO] Epoch: 94 | ValAcc: 0.8200 | ValLoss: 0.0531 \n",
      "\n",
      "[2017-12-02 05:09:56,372 INFO] Epoch: 95 | TrainAcc: 0.9980 | TrainLoss: 0.0057\n",
      "[2017-12-02 05:09:56,671 INFO] Epoch: 95 | ValAcc: 0.8080 | ValLoss: 0.0607 \n",
      "\n",
      "[2017-12-02 05:09:57,297 INFO] Epoch: 96 | TrainAcc: 0.9990 | TrainLoss: 0.0049\n",
      "[2017-12-02 05:09:57,606 INFO] Epoch: 96 | ValAcc: 0.7880 | ValLoss: 0.0719 \n",
      "\n",
      "[2017-12-02 05:09:58,238 INFO] Epoch: 97 | TrainAcc: 1.0000 | TrainLoss: 0.0044\n",
      "[2017-12-02 05:09:58,541 INFO] Epoch: 97 | ValAcc: 0.8220 | ValLoss: 0.0563 \n",
      "\n",
      "[2017-12-02 05:09:59,179 INFO] Epoch: 98 | TrainAcc: 1.0000 | TrainLoss: 0.0041\n",
      "[2017-12-02 05:09:59,477 INFO] Epoch: 98 | ValAcc: 0.8500 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:10:00,119 INFO] Epoch: 99 | TrainAcc: 1.0000 | TrainLoss: 0.0042\n",
      "[2017-12-02 05:10:00,428 INFO] Epoch: 99 | ValAcc: 0.8470 | ValLoss: 0.0507 \n",
      "\n",
      "[2017-12-02 05:10:01,068 INFO] Epoch: 100 | TrainAcc: 1.0000 | TrainLoss: 0.0041\n",
      "[2017-12-02 05:10:01,364 INFO] Epoch: 100 | ValAcc: 0.8530 | ValLoss: 0.0484 \n",
      "\n",
      "[2017-12-02 05:10:02,002 INFO] Epoch: 101 | TrainAcc: 1.0000 | TrainLoss: 0.0043\n",
      "[2017-12-02 05:10:02,318 INFO] Epoch: 101 | ValAcc: 0.8530 | ValLoss: 0.0449 \n",
      "\n",
      "[2017-12-02 05:10:02,956 INFO] Epoch: 102 | TrainAcc: 0.9990 | TrainLoss: 0.0041\n",
      "[2017-12-02 05:10:03,266 INFO] Epoch: 102 | ValAcc: 0.8430 | ValLoss: 0.0467 \n",
      "\n",
      "[2017-12-02 05:10:03,916 INFO] Epoch: 103 | TrainAcc: 1.0000 | TrainLoss: 0.0038\n",
      "[2017-12-02 05:10:04,220 INFO] Epoch: 103 | ValAcc: 0.8640 | ValLoss: 0.0418 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:10:04,864 INFO] Epoch: 104 | TrainAcc: 1.0000 | TrainLoss: 0.0035\n",
      "[2017-12-02 05:10:05,182 INFO] Epoch: 104 | ValAcc: 0.8610 | ValLoss: 0.0469 \n",
      "\n",
      "[2017-12-02 05:10:05,826 INFO] Epoch: 105 | TrainAcc: 1.0000 | TrainLoss: 0.0041\n",
      "[2017-12-02 05:10:06,131 INFO] Epoch: 105 | ValAcc: 0.8520 | ValLoss: 0.0454 \n",
      "\n",
      "[2017-12-02 05:10:06,773 INFO] Epoch: 106 | TrainAcc: 1.0000 | TrainLoss: 0.0036\n",
      "[2017-12-02 05:10:07,083 INFO] Epoch: 106 | ValAcc: 0.8270 | ValLoss: 0.0526 \n",
      "\n",
      "[2017-12-02 05:10:07,726 INFO] Epoch: 107 | TrainAcc: 1.0000 | TrainLoss: 0.0040\n",
      "[2017-12-02 05:10:08,030 INFO] Epoch: 107 | ValAcc: 0.8590 | ValLoss: 0.0449 \n",
      "\n",
      "[2017-12-02 05:10:08,667 INFO] Epoch: 108 | TrainAcc: 1.0000 | TrainLoss: 0.0033\n",
      "[2017-12-02 05:10:08,959 INFO] Epoch: 108 | ValAcc: 0.7980 | ValLoss: 0.0575 \n",
      "\n",
      "[2017-12-02 05:10:09,575 INFO] Epoch: 109 | TrainAcc: 1.0000 | TrainLoss: 0.0034\n",
      "[2017-12-02 05:10:09,876 INFO] Epoch: 109 | ValAcc: 0.8250 | ValLoss: 0.0530 \n",
      "\n",
      "[2017-12-02 05:10:10,502 INFO] Epoch: 110 | TrainAcc: 1.0000 | TrainLoss: 0.0034\n",
      "[2017-12-02 05:10:10,805 INFO] Epoch: 110 | ValAcc: 0.8380 | ValLoss: 0.0488 \n",
      "\n",
      "[2017-12-02 05:10:11,414 INFO] Epoch: 111 | TrainAcc: 1.0000 | TrainLoss: 0.0033\n",
      "[2017-12-02 05:10:11,707 INFO] Epoch: 111 | ValAcc: 0.8440 | ValLoss: 0.0503 \n",
      "\n",
      "[2017-12-02 05:10:12,319 INFO] Epoch: 112 | TrainAcc: 1.0000 | TrainLoss: 0.0031\n",
      "[2017-12-02 05:10:12,614 INFO] Epoch: 112 | ValAcc: 0.7750 | ValLoss: 0.0699 \n",
      "\n",
      "[2017-12-02 05:10:13,232 INFO] Epoch: 113 | TrainAcc: 1.0000 | TrainLoss: 0.0030\n",
      "[2017-12-02 05:10:13,531 INFO] Epoch: 113 | ValAcc: 0.8490 | ValLoss: 0.0470 \n",
      "\n",
      "[2017-12-02 05:10:14,144 INFO] Epoch: 114 | TrainAcc: 1.0000 | TrainLoss: 0.0028\n",
      "[2017-12-02 05:10:14,445 INFO] Epoch: 114 | ValAcc: 0.8610 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:10:15,067 INFO] Epoch: 115 | TrainAcc: 1.0000 | TrainLoss: 0.0027\n",
      "[2017-12-02 05:10:15,361 INFO] Epoch: 115 | ValAcc: 0.8410 | ValLoss: 0.0499 \n",
      "\n",
      "[2017-12-02 05:10:15,984 INFO] Epoch: 116 | TrainAcc: 1.0000 | TrainLoss: 0.0029\n",
      "[2017-12-02 05:10:16,280 INFO] Epoch: 116 | ValAcc: 0.8660 | ValLoss: 0.0400 \n",
      "\n",
      "[2017-12-02 05:10:16,899 INFO] Epoch: 117 | TrainAcc: 1.0000 | TrainLoss: 0.0030\n",
      "[2017-12-02 05:10:17,202 INFO] Epoch: 117 | ValAcc: 0.8260 | ValLoss: 0.0580 \n",
      "\n",
      "[2017-12-02 05:10:17,829 INFO] Epoch: 118 | TrainAcc: 1.0000 | TrainLoss: 0.0033\n",
      "[2017-12-02 05:10:18,124 INFO] Epoch: 118 | ValAcc: 0.8210 | ValLoss: 0.0527 \n",
      "\n",
      "[2017-12-02 05:10:18,744 INFO] Epoch: 119 | TrainAcc: 1.0000 | TrainLoss: 0.0035\n",
      "[2017-12-02 05:10:19,075 INFO] Epoch: 119 | ValAcc: 0.8100 | ValLoss: 0.0605 \n",
      "\n",
      "[2017-12-02 05:10:19,691 INFO] Epoch: 120 | TrainAcc: 0.9990 | TrainLoss: 0.0043\n",
      "[2017-12-02 05:10:19,986 INFO] Epoch: 120 | ValAcc: 0.8120 | ValLoss: 0.0613 \n",
      "\n",
      "[2017-12-02 05:10:20,610 INFO] Epoch: 121 | TrainAcc: 0.9980 | TrainLoss: 0.0040\n",
      "[2017-12-02 05:10:20,933 INFO] Epoch: 121 | ValAcc: 0.7700 | ValLoss: 0.0732 \n",
      "\n",
      "[2017-12-02 05:10:21,550 INFO] Epoch: 122 | TrainAcc: 0.9990 | TrainLoss: 0.0036\n",
      "[2017-12-02 05:10:21,843 INFO] Epoch: 122 | ValAcc: 0.8450 | ValLoss: 0.0474 \n",
      "\n",
      "[2017-12-02 05:10:22,459 INFO] Epoch: 123 | TrainAcc: 1.0000 | TrainLoss: 0.0030\n",
      "[2017-12-02 05:10:22,766 INFO] Epoch: 123 | ValAcc: 0.8480 | ValLoss: 0.0484 \n",
      "\n",
      "[2017-12-02 05:10:23,387 INFO] Epoch: 124 | TrainAcc: 1.0000 | TrainLoss: 0.0027\n",
      "[2017-12-02 05:10:23,688 INFO] Epoch: 124 | ValAcc: 0.8300 | ValLoss: 0.0555 \n",
      "\n",
      "[2017-12-02 05:10:24,300 INFO] Epoch: 125 | TrainAcc: 1.0000 | TrainLoss: 0.0024\n",
      "[2017-12-02 05:10:24,602 INFO] Epoch: 125 | ValAcc: 0.8620 | ValLoss: 0.0439 \n",
      "\n",
      "[2017-12-02 05:10:25,214 INFO] Epoch: 126 | TrainAcc: 1.0000 | TrainLoss: 0.0024\n",
      "[2017-12-02 05:10:25,507 INFO] Epoch: 126 | ValAcc: 0.8730 | ValLoss: 0.0380 \n",
      "\n",
      "[2017-12-02 05:10:26,140 INFO] Epoch: 127 | TrainAcc: 1.0000 | TrainLoss: 0.0023\n",
      "[2017-12-02 05:10:26,437 INFO] Epoch: 127 | ValAcc: 0.8760 | ValLoss: 0.0388 \n",
      "\n",
      "[2017-12-02 05:10:27,073 INFO] Epoch: 128 | TrainAcc: 1.0000 | TrainLoss: 0.0022\n",
      "[2017-12-02 05:10:27,367 INFO] Epoch: 128 | ValAcc: 0.8760 | ValLoss: 0.0394 \n",
      "\n",
      "[2017-12-02 05:10:27,995 INFO] Epoch: 129 | TrainAcc: 1.0000 | TrainLoss: 0.0021\n",
      "[2017-12-02 05:10:28,299 INFO] Epoch: 129 | ValAcc: 0.8650 | ValLoss: 0.0397 \n",
      "\n",
      "[2017-12-02 05:10:28,917 INFO] Epoch: 130 | TrainAcc: 1.0000 | TrainLoss: 0.0021\n",
      "[2017-12-02 05:10:29,213 INFO] Epoch: 130 | ValAcc: 0.8550 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:10:29,838 INFO] Epoch: 131 | TrainAcc: 1.0000 | TrainLoss: 0.0022\n",
      "[2017-12-02 05:10:30,130 INFO] Epoch: 131 | ValAcc: 0.8530 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:10:30,755 INFO] Epoch: 132 | TrainAcc: 1.0000 | TrainLoss: 0.0020\n",
      "[2017-12-02 05:10:31,058 INFO] Epoch: 132 | ValAcc: 0.8730 | ValLoss: 0.0374 \n",
      "\n",
      "[2017-12-02 05:10:31,678 INFO] Epoch: 133 | TrainAcc: 1.0000 | TrainLoss: 0.0020\n",
      "[2017-12-02 05:10:31,970 INFO] Epoch: 133 | ValAcc: 0.8760 | ValLoss: 0.0389 \n",
      "\n",
      "[2017-12-02 05:10:32,596 INFO] Epoch: 134 | TrainAcc: 1.0000 | TrainLoss: 0.0019\n",
      "[2017-12-02 05:10:32,892 INFO] Epoch: 134 | ValAcc: 0.8750 | ValLoss: 0.0386 \n",
      "\n",
      "[2017-12-02 05:10:33,515 INFO] Epoch: 135 | TrainAcc: 1.0000 | TrainLoss: 0.0020\n",
      "[2017-12-02 05:10:33,807 INFO] Epoch: 135 | ValAcc: 0.8750 | ValLoss: 0.0393 \n",
      "\n",
      "[2017-12-02 05:10:34,434 INFO] Epoch: 136 | TrainAcc: 1.0000 | TrainLoss: 0.0019\n",
      "[2017-12-02 05:10:34,730 INFO] Epoch: 136 | ValAcc: 0.8570 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:10:35,340 INFO] Epoch: 137 | TrainAcc: 1.0000 | TrainLoss: 0.0021\n",
      "[2017-12-02 05:10:35,631 INFO] Epoch: 137 | ValAcc: 0.8650 | ValLoss: 0.0401 \n",
      "\n",
      "[2017-12-02 05:10:36,260 INFO] Epoch: 138 | TrainAcc: 1.0000 | TrainLoss: 0.0019\n",
      "[2017-12-02 05:10:36,550 INFO] Epoch: 138 | ValAcc: 0.8630 | ValLoss: 0.0441 \n",
      "\n",
      "[2017-12-02 05:10:37,166 INFO] Epoch: 139 | TrainAcc: 1.0000 | TrainLoss: 0.0018\n",
      "[2017-12-02 05:10:37,465 INFO] Epoch: 139 | ValAcc: 0.8500 | ValLoss: 0.0444 \n",
      "\n",
      "[2017-12-02 05:10:38,094 INFO] Epoch: 140 | TrainAcc: 1.0000 | TrainLoss: 0.0019\n",
      "[2017-12-02 05:10:38,389 INFO] Epoch: 140 | ValAcc: 0.8830 | ValLoss: 0.0394 \n",
      "\n",
      "[2017-12-02 05:10:39,017 INFO] Epoch: 141 | TrainAcc: 1.0000 | TrainLoss: 0.0019\n",
      "[2017-12-02 05:10:39,311 INFO] Epoch: 141 | ValAcc: 0.8630 | ValLoss: 0.0424 \n",
      "\n",
      "[2017-12-02 05:10:39,976 INFO] Epoch: 142 | TrainAcc: 1.0000 | TrainLoss: 0.0019\n",
      "[2017-12-02 05:10:40,358 INFO] Epoch: 142 | ValAcc: 0.8730 | ValLoss: 0.0397 \n",
      "\n",
      "[2017-12-02 05:10:41,025 INFO] Epoch: 143 | TrainAcc: 1.0000 | TrainLoss: 0.0018\n",
      "[2017-12-02 05:10:41,313 INFO] Epoch: 143 | ValAcc: 0.8630 | ValLoss: 0.0447 \n",
      "\n",
      "[2017-12-02 05:10:41,945 INFO] Epoch: 144 | TrainAcc: 1.0000 | TrainLoss: 0.0018\n",
      "[2017-12-02 05:10:42,242 INFO] Epoch: 144 | ValAcc: 0.8530 | ValLoss: 0.0471 \n",
      "\n",
      "[2017-12-02 05:10:42,848 INFO] Epoch: 145 | TrainAcc: 1.0000 | TrainLoss: 0.0018\n",
      "[2017-12-02 05:10:43,145 INFO] Epoch: 145 | ValAcc: 0.8640 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:10:43,768 INFO] Epoch: 146 | TrainAcc: 1.0000 | TrainLoss: 0.0020\n",
      "[2017-12-02 05:10:44,062 INFO] Epoch: 146 | ValAcc: 0.8670 | ValLoss: 0.0439 \n",
      "\n",
      "[2017-12-02 05:10:44,693 INFO] Epoch: 147 | TrainAcc: 1.0000 | TrainLoss: 0.0016\n",
      "[2017-12-02 05:10:44,995 INFO] Epoch: 147 | ValAcc: 0.8720 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:10:45,612 INFO] Epoch: 148 | TrainAcc: 1.0000 | TrainLoss: 0.0015\n",
      "[2017-12-02 05:10:45,906 INFO] Epoch: 148 | ValAcc: 0.8790 | ValLoss: 0.0377 \n",
      "\n",
      "[2017-12-02 05:10:46,536 INFO] Epoch: 149 | TrainAcc: 1.0000 | TrainLoss: 0.0015\n",
      "[2017-12-02 05:10:46,842 INFO] Epoch: 149 | ValAcc: 0.8760 | ValLoss: 0.0384 \n",
      "\n",
      "[2017-12-02 05:10:47,480 INFO] Epoch: 150 | TrainAcc: 1.0000 | TrainLoss: 0.0014\n",
      "[2017-12-02 05:10:47,783 INFO] Epoch: 150 | ValAcc: 0.8740 | ValLoss: 0.0380 \n",
      "\n",
      "[2017-12-02 05:10:48,560 INFO] Epoch: 151 | TrainAcc: 1.0000 | TrainLoss: 0.0015\n",
      "[2017-12-02 05:10:48,892 INFO] Epoch: 151 | ValAcc: 0.8740 | ValLoss: 0.0380 \n",
      "\n",
      "[2017-12-02 05:10:49,580 INFO] Epoch: 152 | TrainAcc: 1.0000 | TrainLoss: 0.0016\n",
      "[2017-12-02 05:10:49,966 INFO] Epoch: 152 | ValAcc: 0.8510 | ValLoss: 0.0475 \n",
      "\n",
      "[2017-12-02 05:10:50,677 INFO] Epoch: 153 | TrainAcc: 1.0000 | TrainLoss: 0.0015\n",
      "[2017-12-02 05:10:51,028 INFO] Epoch: 153 | ValAcc: 0.8710 | ValLoss: 0.0385 \n",
      "\n",
      "[2017-12-02 05:10:51,781 INFO] Epoch: 154 | TrainAcc: 1.0000 | TrainLoss: 0.0015\n",
      "[2017-12-02 05:10:52,105 INFO] Epoch: 154 | ValAcc: 0.8770 | ValLoss: 0.0377 \n",
      "\n",
      "[2017-12-02 05:10:52,765 INFO] Epoch: 155 | TrainAcc: 1.0000 | TrainLoss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:10:53,074 INFO] Epoch: 155 | ValAcc: 0.8760 | ValLoss: 0.0402 \n",
      "\n",
      "[2017-12-02 05:10:53,735 INFO] Epoch: 156 | TrainAcc: 1.0000 | TrainLoss: 0.0017\n",
      "[2017-12-02 05:10:54,045 INFO] Epoch: 156 | ValAcc: 0.8650 | ValLoss: 0.0463 \n",
      "\n",
      "[2017-12-02 05:10:54,698 INFO] Epoch: 157 | TrainAcc: 1.0000 | TrainLoss: 0.0016\n",
      "[2017-12-02 05:10:55,032 INFO] Epoch: 157 | ValAcc: 0.8340 | ValLoss: 0.0510 \n",
      "\n",
      "[2017-12-02 05:10:55,880 INFO] Epoch: 158 | TrainAcc: 1.0000 | TrainLoss: 0.0018\n",
      "[2017-12-02 05:10:56,196 INFO] Epoch: 158 | ValAcc: 0.8570 | ValLoss: 0.0452 \n",
      "\n",
      "[2017-12-02 05:10:56,901 INFO] Epoch: 159 | TrainAcc: 1.0000 | TrainLoss: 0.0014\n",
      "[2017-12-02 05:10:57,222 INFO] Epoch: 159 | ValAcc: 0.8650 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:10:58,022 INFO] Epoch: 160 | TrainAcc: 1.0000 | TrainLoss: 0.0014\n",
      "[2017-12-02 05:10:58,363 INFO] Epoch: 160 | ValAcc: 0.8730 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:10:59,012 INFO] Epoch: 161 | TrainAcc: 1.0000 | TrainLoss: 0.0013\n",
      "[2017-12-02 05:10:59,313 INFO] Epoch: 161 | ValAcc: 0.8720 | ValLoss: 0.0399 \n",
      "\n",
      "[2017-12-02 05:10:59,980 INFO] Epoch: 162 | TrainAcc: 1.0000 | TrainLoss: 0.0014\n",
      "[2017-12-02 05:11:00,299 INFO] Epoch: 162 | ValAcc: 0.8740 | ValLoss: 0.0389 \n",
      "\n",
      "[2017-12-02 05:11:00,948 INFO] Epoch: 163 | TrainAcc: 1.0000 | TrainLoss: 0.0013\n",
      "[2017-12-02 05:11:01,289 INFO] Epoch: 163 | ValAcc: 0.8790 | ValLoss: 0.0379 \n",
      "\n",
      "[2017-12-02 05:11:01,921 INFO] Epoch: 164 | TrainAcc: 1.0000 | TrainLoss: 0.0014\n",
      "[2017-12-02 05:11:02,231 INFO] Epoch: 164 | ValAcc: 0.8760 | ValLoss: 0.0390 \n",
      "\n",
      "[2017-12-02 05:11:02,864 INFO] Epoch: 165 | TrainAcc: 1.0000 | TrainLoss: 0.0014\n",
      "[2017-12-02 05:11:03,164 INFO] Epoch: 165 | ValAcc: 0.8360 | ValLoss: 0.0498 \n",
      "\n",
      "[2017-12-02 05:11:03,796 INFO] Epoch: 166 | TrainAcc: 1.0000 | TrainLoss: 0.0015\n",
      "[2017-12-02 05:11:04,103 INFO] Epoch: 166 | ValAcc: 0.8560 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:11:04,744 INFO] Epoch: 167 | TrainAcc: 1.0000 | TrainLoss: 0.0013\n",
      "[2017-12-02 05:11:05,046 INFO] Epoch: 167 | ValAcc: 0.8800 | ValLoss: 0.0393 \n",
      "\n",
      "[2017-12-02 05:11:05,671 INFO] Epoch: 168 | TrainAcc: 1.0000 | TrainLoss: 0.0015\n",
      "[2017-12-02 05:11:05,967 INFO] Epoch: 168 | ValAcc: 0.8640 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:11:06,591 INFO] Epoch: 169 | TrainAcc: 1.0000 | TrainLoss: 0.0014\n",
      "[2017-12-02 05:11:06,885 INFO] Epoch: 169 | ValAcc: 0.8740 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:11:07,494 INFO] Epoch: 170 | TrainAcc: 1.0000 | TrainLoss: 0.0013\n",
      "[2017-12-02 05:11:07,805 INFO] Epoch: 170 | ValAcc: 0.8810 | ValLoss: 0.0385 \n",
      "\n",
      "[2017-12-02 05:11:08,431 INFO] Epoch: 171 | TrainAcc: 1.0000 | TrainLoss: 0.0014\n",
      "[2017-12-02 05:11:08,726 INFO] Epoch: 171 | ValAcc: 0.8740 | ValLoss: 0.0401 \n",
      "\n",
      "[2017-12-02 05:11:09,382 INFO] Epoch: 172 | TrainAcc: 1.0000 | TrainLoss: 0.0013\n",
      "[2017-12-02 05:11:09,678 INFO] Epoch: 172 | ValAcc: 0.8740 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:11:10,294 INFO] Epoch: 173 | TrainAcc: 1.0000 | TrainLoss: 0.0012\n",
      "[2017-12-02 05:11:10,601 INFO] Epoch: 173 | ValAcc: 0.8760 | ValLoss: 0.0396 \n",
      "\n",
      "[2017-12-02 05:11:11,222 INFO] Epoch: 174 | TrainAcc: 1.0000 | TrainLoss: 0.0012\n",
      "[2017-12-02 05:11:11,570 INFO] Epoch: 174 | ValAcc: 0.8730 | ValLoss: 0.0398 \n",
      "\n",
      "[2017-12-02 05:11:12,231 INFO] Epoch: 175 | TrainAcc: 1.0000 | TrainLoss: 0.0012\n",
      "[2017-12-02 05:11:12,528 INFO] Epoch: 175 | ValAcc: 0.8730 | ValLoss: 0.0395 \n",
      "\n",
      "[2017-12-02 05:11:13,154 INFO] Epoch: 176 | TrainAcc: 1.0000 | TrainLoss: 0.0011\n",
      "[2017-12-02 05:11:13,448 INFO] Epoch: 176 | ValAcc: 0.8730 | ValLoss: 0.0388 \n",
      "\n",
      "[2017-12-02 05:11:14,077 INFO] Epoch: 177 | TrainAcc: 1.0000 | TrainLoss: 0.0011\n",
      "[2017-12-02 05:11:14,372 INFO] Epoch: 177 | ValAcc: 0.8770 | ValLoss: 0.0380 \n",
      "\n",
      "[2017-12-02 05:11:14,994 INFO] Epoch: 178 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:15,301 INFO] Epoch: 178 | ValAcc: 0.8820 | ValLoss: 0.0387 \n",
      "\n",
      "[2017-12-02 05:11:15,931 INFO] Epoch: 179 | TrainAcc: 1.0000 | TrainLoss: 0.0012\n",
      "[2017-12-02 05:11:16,232 INFO] Epoch: 179 | ValAcc: 0.8730 | ValLoss: 0.0386 \n",
      "\n",
      "[2017-12-02 05:11:16,840 INFO] Epoch: 180 | TrainAcc: 1.0000 | TrainLoss: 0.0011\n",
      "[2017-12-02 05:11:17,154 INFO] Epoch: 180 | ValAcc: 0.8730 | ValLoss: 0.0385 \n",
      "\n",
      "[2017-12-02 05:11:17,762 INFO] Epoch: 181 | TrainAcc: 1.0000 | TrainLoss: 0.0012\n",
      "[2017-12-02 05:11:18,050 INFO] Epoch: 181 | ValAcc: 0.8780 | ValLoss: 0.0384 \n",
      "\n",
      "[2017-12-02 05:11:18,670 INFO] Epoch: 182 | TrainAcc: 1.0000 | TrainLoss: 0.0011\n",
      "[2017-12-02 05:11:19,007 INFO] Epoch: 182 | ValAcc: 0.8730 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:11:19,632 INFO] Epoch: 183 | TrainAcc: 1.0000 | TrainLoss: 0.0011\n",
      "[2017-12-02 05:11:19,926 INFO] Epoch: 183 | ValAcc: 0.8790 | ValLoss: 0.0383 \n",
      "\n",
      "[2017-12-02 05:11:20,542 INFO] Epoch: 184 | TrainAcc: 1.0000 | TrainLoss: 0.0011\n",
      "[2017-12-02 05:11:20,847 INFO] Epoch: 184 | ValAcc: 0.8580 | ValLoss: 0.0457 \n",
      "\n",
      "[2017-12-02 05:11:21,475 INFO] Epoch: 185 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:21,777 INFO] Epoch: 185 | ValAcc: 0.8730 | ValLoss: 0.0383 \n",
      "\n",
      "[2017-12-02 05:11:22,407 INFO] Epoch: 186 | TrainAcc: 1.0000 | TrainLoss: 0.0011\n",
      "[2017-12-02 05:11:22,714 INFO] Epoch: 186 | ValAcc: 0.8500 | ValLoss: 0.0465 \n",
      "\n",
      "[2017-12-02 05:11:23,341 INFO] Epoch: 187 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:23,635 INFO] Epoch: 187 | ValAcc: 0.8800 | ValLoss: 0.0386 \n",
      "\n",
      "[2017-12-02 05:11:24,250 INFO] Epoch: 188 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:24,556 INFO] Epoch: 188 | ValAcc: 0.8830 | ValLoss: 0.0384 \n",
      "\n",
      "[2017-12-02 05:11:25,186 INFO] Epoch: 189 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:25,484 INFO] Epoch: 189 | ValAcc: 0.8690 | ValLoss: 0.0397 \n",
      "\n",
      "[2017-12-02 05:11:26,098 INFO] Epoch: 190 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:26,391 INFO] Epoch: 190 | ValAcc: 0.8780 | ValLoss: 0.0391 \n",
      "\n",
      "[2017-12-02 05:11:26,999 INFO] Epoch: 191 | TrainAcc: 1.0000 | TrainLoss: 0.0011\n",
      "[2017-12-02 05:11:27,288 INFO] Epoch: 191 | ValAcc: 0.8760 | ValLoss: 0.0402 \n",
      "\n",
      "[2017-12-02 05:11:27,903 INFO] Epoch: 192 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:28,193 INFO] Epoch: 192 | ValAcc: 0.8740 | ValLoss: 0.0402 \n",
      "\n",
      "[2017-12-02 05:11:28,814 INFO] Epoch: 193 | TrainAcc: 1.0000 | TrainLoss: 0.0011\n",
      "[2017-12-02 05:11:29,107 INFO] Epoch: 193 | ValAcc: 0.8690 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:11:29,727 INFO] Epoch: 194 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:30,020 INFO] Epoch: 194 | ValAcc: 0.8760 | ValLoss: 0.0397 \n",
      "\n",
      "[2017-12-02 05:11:30,641 INFO] Epoch: 195 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:30,934 INFO] Epoch: 195 | ValAcc: 0.8760 | ValLoss: 0.0381 \n",
      "\n",
      "[2017-12-02 05:11:31,564 INFO] Epoch: 196 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:31,858 INFO] Epoch: 196 | ValAcc: 0.8540 | ValLoss: 0.0458 \n",
      "\n",
      "[2017-12-02 05:11:32,479 INFO] Epoch: 197 | TrainAcc: 1.0000 | TrainLoss: 0.0009\n",
      "[2017-12-02 05:11:32,776 INFO] Epoch: 197 | ValAcc: 0.8800 | ValLoss: 0.0389 \n",
      "\n",
      "[2017-12-02 05:11:33,387 INFO] Epoch: 198 | TrainAcc: 1.0000 | TrainLoss: 0.0011\n",
      "[2017-12-02 05:11:33,681 INFO] Epoch: 198 | ValAcc: 0.8670 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:11:34,307 INFO] Epoch: 199 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:34,595 INFO] Epoch: 199 | ValAcc: 0.8630 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:11:35,206 INFO] Epoch: 200 | TrainAcc: 1.0000 | TrainLoss: 0.0009\n",
      "[2017-12-02 05:11:35,506 INFO] Epoch: 200 | ValAcc: 0.8640 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:11:36,137 INFO] Epoch: 201 | TrainAcc: 1.0000 | TrainLoss: 0.0009\n",
      "[2017-12-02 05:11:36,430 INFO] Epoch: 201 | ValAcc: 0.8830 | ValLoss: 0.0395 \n",
      "\n",
      "[2017-12-02 05:11:37,053 INFO] Epoch: 202 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:37,351 INFO] Epoch: 202 | ValAcc: 0.8740 | ValLoss: 0.0402 \n",
      "\n",
      "[2017-12-02 05:11:37,975 INFO] Epoch: 203 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:11:38,272 INFO] Epoch: 203 | ValAcc: 0.8760 | ValLoss: 0.0396 \n",
      "\n",
      "[2017-12-02 05:11:38,883 INFO] Epoch: 204 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:39,174 INFO] Epoch: 204 | ValAcc: 0.8790 | ValLoss: 0.0388 \n",
      "\n",
      "[2017-12-02 05:11:39,792 INFO] Epoch: 205 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:40,083 INFO] Epoch: 205 | ValAcc: 0.8730 | ValLoss: 0.0395 \n",
      "\n",
      "[2017-12-02 05:11:40,722 INFO] Epoch: 206 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:41,018 INFO] Epoch: 206 | ValAcc: 0.8710 | ValLoss: 0.0426 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:11:41,651 INFO] Epoch: 207 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:41,955 INFO] Epoch: 207 | ValAcc: 0.8720 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:11:42,566 INFO] Epoch: 208 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:42,864 INFO] Epoch: 208 | ValAcc: 0.8780 | ValLoss: 0.0379 \n",
      "\n",
      "[2017-12-02 05:11:43,492 INFO] Epoch: 209 | TrainAcc: 1.0000 | TrainLoss: 0.0009\n",
      "[2017-12-02 05:11:43,785 INFO] Epoch: 209 | ValAcc: 0.8720 | ValLoss: 0.0396 \n",
      "\n",
      "[2017-12-02 05:11:44,408 INFO] Epoch: 210 | TrainAcc: 1.0000 | TrainLoss: 0.0009\n",
      "[2017-12-02 05:11:44,701 INFO] Epoch: 210 | ValAcc: 0.8620 | ValLoss: 0.0469 \n",
      "\n",
      "[2017-12-02 05:11:45,326 INFO] Epoch: 211 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:11:45,619 INFO] Epoch: 211 | ValAcc: 0.8730 | ValLoss: 0.0409 \n",
      "\n",
      "[2017-12-02 05:11:46,241 INFO] Epoch: 212 | TrainAcc: 1.0000 | TrainLoss: 0.0010\n",
      "[2017-12-02 05:11:46,537 INFO] Epoch: 212 | ValAcc: 0.8790 | ValLoss: 0.0382 \n",
      "\n",
      "[2017-12-02 05:11:47,148 INFO] Epoch: 213 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:11:47,437 INFO] Epoch: 213 | ValAcc: 0.8770 | ValLoss: 0.0402 \n",
      "\n",
      "[2017-12-02 05:11:48,056 INFO] Epoch: 214 | TrainAcc: 1.0000 | TrainLoss: 0.0009\n",
      "[2017-12-02 05:11:48,346 INFO] Epoch: 214 | ValAcc: 0.8780 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:11:48,946 INFO] Epoch: 215 | TrainAcc: 1.0000 | TrainLoss: 0.0009\n",
      "[2017-12-02 05:11:49,250 INFO] Epoch: 215 | ValAcc: 0.8750 | ValLoss: 0.0401 \n",
      "\n",
      "[2017-12-02 05:11:49,871 INFO] Epoch: 216 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:11:50,167 INFO] Epoch: 216 | ValAcc: 0.8730 | ValLoss: 0.0391 \n",
      "\n",
      "[2017-12-02 05:11:50,778 INFO] Epoch: 217 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:11:51,079 INFO] Epoch: 217 | ValAcc: 0.8760 | ValLoss: 0.0392 \n",
      "\n",
      "[2017-12-02 05:11:51,710 INFO] Epoch: 218 | TrainAcc: 1.0000 | TrainLoss: 0.0009\n",
      "[2017-12-02 05:11:52,008 INFO] Epoch: 218 | ValAcc: 0.8750 | ValLoss: 0.0402 \n",
      "\n",
      "[2017-12-02 05:11:52,635 INFO] Epoch: 219 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:11:52,929 INFO] Epoch: 219 | ValAcc: 0.8730 | ValLoss: 0.0406 \n",
      "\n",
      "[2017-12-02 05:11:53,538 INFO] Epoch: 220 | TrainAcc: 1.0000 | TrainLoss: 0.0009\n",
      "[2017-12-02 05:11:53,830 INFO] Epoch: 220 | ValAcc: 0.8770 | ValLoss: 0.0389 \n",
      "\n",
      "[2017-12-02 05:11:54,452 INFO] Epoch: 221 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:11:54,747 INFO] Epoch: 221 | ValAcc: 0.8800 | ValLoss: 0.0388 \n",
      "\n",
      "[2017-12-02 05:11:55,367 INFO] Epoch: 222 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:11:55,668 INFO] Epoch: 222 | ValAcc: 0.8730 | ValLoss: 0.0408 \n",
      "\n",
      "[2017-12-02 05:11:56,283 INFO] Epoch: 223 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:11:56,580 INFO] Epoch: 223 | ValAcc: 0.8750 | ValLoss: 0.0392 \n",
      "\n",
      "[2017-12-02 05:11:57,206 INFO] Epoch: 224 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:11:57,515 INFO] Epoch: 224 | ValAcc: 0.8860 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:11:58,158 INFO] Epoch: 225 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:11:58,453 INFO] Epoch: 225 | ValAcc: 0.8700 | ValLoss: 0.0403 \n",
      "\n",
      "[2017-12-02 05:11:59,082 INFO] Epoch: 226 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:11:59,372 INFO] Epoch: 226 | ValAcc: 0.8560 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:11:59,995 INFO] Epoch: 227 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:12:00,295 INFO] Epoch: 227 | ValAcc: 0.8760 | ValLoss: 0.0387 \n",
      "\n",
      "[2017-12-02 05:12:00,910 INFO] Epoch: 228 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:12:01,205 INFO] Epoch: 228 | ValAcc: 0.8860 | ValLoss: 0.0395 \n",
      "\n",
      "[2017-12-02 05:12:01,832 INFO] Epoch: 229 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:12:02,119 INFO] Epoch: 229 | ValAcc: 0.8720 | ValLoss: 0.0408 \n",
      "\n",
      "[2017-12-02 05:12:02,733 INFO] Epoch: 230 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:12:03,026 INFO] Epoch: 230 | ValAcc: 0.8790 | ValLoss: 0.0391 \n",
      "\n",
      "[2017-12-02 05:12:03,666 INFO] Epoch: 231 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:12:03,972 INFO] Epoch: 231 | ValAcc: 0.8870 | ValLoss: 0.0397 \n",
      "\n",
      "[2017-12-02 05:12:04,598 INFO] Epoch: 232 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:04,897 INFO] Epoch: 232 | ValAcc: 0.8850 | ValLoss: 0.0390 \n",
      "\n",
      "[2017-12-02 05:12:05,519 INFO] Epoch: 233 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:05,820 INFO] Epoch: 233 | ValAcc: 0.8640 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:12:06,439 INFO] Epoch: 234 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:12:06,735 INFO] Epoch: 234 | ValAcc: 0.8720 | ValLoss: 0.0389 \n",
      "\n",
      "[2017-12-02 05:12:07,361 INFO] Epoch: 235 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:12:07,671 INFO] Epoch: 235 | ValAcc: 0.8740 | ValLoss: 0.0393 \n",
      "\n",
      "[2017-12-02 05:12:08,303 INFO] Epoch: 236 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:08,598 INFO] Epoch: 236 | ValAcc: 0.8760 | ValLoss: 0.0407 \n",
      "\n",
      "[2017-12-02 05:12:09,206 INFO] Epoch: 237 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:12:09,515 INFO] Epoch: 237 | ValAcc: 0.8820 | ValLoss: 0.0387 \n",
      "\n",
      "[2017-12-02 05:12:10,128 INFO] Epoch: 238 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:10,417 INFO] Epoch: 238 | ValAcc: 0.8760 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:12:11,056 INFO] Epoch: 239 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:11,360 INFO] Epoch: 239 | ValAcc: 0.8830 | ValLoss: 0.0395 \n",
      "\n",
      "[2017-12-02 05:12:12,007 INFO] Epoch: 240 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:12,295 INFO] Epoch: 240 | ValAcc: 0.8680 | ValLoss: 0.0426 \n",
      "\n",
      "[2017-12-02 05:12:12,919 INFO] Epoch: 241 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:13,206 INFO] Epoch: 241 | ValAcc: 0.8760 | ValLoss: 0.0395 \n",
      "\n",
      "[2017-12-02 05:12:13,819 INFO] Epoch: 242 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:14,120 INFO] Epoch: 242 | ValAcc: 0.8800 | ValLoss: 0.0392 \n",
      "\n",
      "[2017-12-02 05:12:14,741 INFO] Epoch: 243 | TrainAcc: 1.0000 | TrainLoss: 0.0008\n",
      "[2017-12-02 05:12:15,035 INFO] Epoch: 243 | ValAcc: 0.8480 | ValLoss: 0.0523 \n",
      "\n",
      "[2017-12-02 05:12:15,664 INFO] Epoch: 244 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:15,958 INFO] Epoch: 244 | ValAcc: 0.8720 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:12:16,580 INFO] Epoch: 245 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:16,876 INFO] Epoch: 245 | ValAcc: 0.8730 | ValLoss: 0.0424 \n",
      "\n",
      "[2017-12-02 05:12:17,501 INFO] Epoch: 246 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:17,790 INFO] Epoch: 246 | ValAcc: 0.8830 | ValLoss: 0.0407 \n",
      "\n",
      "[2017-12-02 05:12:18,402 INFO] Epoch: 247 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:18,700 INFO] Epoch: 247 | ValAcc: 0.8740 | ValLoss: 0.0395 \n",
      "\n",
      "[2017-12-02 05:12:19,347 INFO] Epoch: 248 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:19,633 INFO] Epoch: 248 | ValAcc: 0.8800 | ValLoss: 0.0384 \n",
      "\n",
      "[2017-12-02 05:12:20,253 INFO] Epoch: 249 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:20,567 INFO] Epoch: 249 | ValAcc: 0.8840 | ValLoss: 0.0385 \n",
      "\n",
      "[2017-12-02 05:12:21,192 INFO] Epoch: 250 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:21,488 INFO] Epoch: 250 | ValAcc: 0.8780 | ValLoss: 0.0395 \n",
      "\n",
      "[2017-12-02 05:12:22,117 INFO] Epoch: 251 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:22,416 INFO] Epoch: 251 | ValAcc: 0.8810 | ValLoss: 0.0391 \n",
      "\n",
      "[2017-12-02 05:12:23,048 INFO] Epoch: 252 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:23,351 INFO] Epoch: 252 | ValAcc: 0.8690 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:12:23,986 INFO] Epoch: 253 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:24,282 INFO] Epoch: 253 | ValAcc: 0.8710 | ValLoss: 0.0399 \n",
      "\n",
      "[2017-12-02 05:12:24,898 INFO] Epoch: 254 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:25,189 INFO] Epoch: 254 | ValAcc: 0.8800 | ValLoss: 0.0389 \n",
      "\n",
      "[2017-12-02 05:12:25,818 INFO] Epoch: 255 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:26,107 INFO] Epoch: 255 | ValAcc: 0.8790 | ValLoss: 0.0397 \n",
      "\n",
      "[2017-12-02 05:12:26,727 INFO] Epoch: 256 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:27,021 INFO] Epoch: 256 | ValAcc: 0.8800 | ValLoss: 0.0395 \n",
      "\n",
      "[2017-12-02 05:12:27,638 INFO] Epoch: 257 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:27,936 INFO] Epoch: 257 | ValAcc: 0.8800 | ValLoss: 0.0387 \n",
      "\n",
      "[2017-12-02 05:12:28,557 INFO] Epoch: 258 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:12:28,849 INFO] Epoch: 258 | ValAcc: 0.8800 | ValLoss: 0.0396 \n",
      "\n",
      "[2017-12-02 05:12:29,484 INFO] Epoch: 259 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:29,773 INFO] Epoch: 259 | ValAcc: 0.8740 | ValLoss: 0.0390 \n",
      "\n",
      "[2017-12-02 05:12:30,401 INFO] Epoch: 260 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:30,695 INFO] Epoch: 260 | ValAcc: 0.8730 | ValLoss: 0.0409 \n",
      "\n",
      "[2017-12-02 05:12:31,323 INFO] Epoch: 261 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:31,617 INFO] Epoch: 261 | ValAcc: 0.8680 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:12:32,252 INFO] Epoch: 262 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:32,551 INFO] Epoch: 262 | ValAcc: 0.8840 | ValLoss: 0.0402 \n",
      "\n",
      "[2017-12-02 05:12:33,169 INFO] Epoch: 263 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:33,463 INFO] Epoch: 263 | ValAcc: 0.8880 | ValLoss: 0.0389 \n",
      "\n",
      "[2017-12-02 05:12:34,077 INFO] Epoch: 264 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:34,368 INFO] Epoch: 264 | ValAcc: 0.8760 | ValLoss: 0.0391 \n",
      "\n",
      "[2017-12-02 05:12:35,006 INFO] Epoch: 265 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:35,303 INFO] Epoch: 265 | ValAcc: 0.8780 | ValLoss: 0.0401 \n",
      "\n",
      "[2017-12-02 05:12:35,928 INFO] Epoch: 266 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:36,220 INFO] Epoch: 266 | ValAcc: 0.8860 | ValLoss: 0.0398 \n",
      "\n",
      "[2017-12-02 05:12:36,849 INFO] Epoch: 267 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:37,147 INFO] Epoch: 267 | ValAcc: 0.8390 | ValLoss: 0.0571 \n",
      "\n",
      "[2017-12-02 05:12:37,762 INFO] Epoch: 268 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:38,063 INFO] Epoch: 268 | ValAcc: 0.8610 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:12:38,677 INFO] Epoch: 269 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:38,960 INFO] Epoch: 269 | ValAcc: 0.8790 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:12:39,570 INFO] Epoch: 270 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:39,859 INFO] Epoch: 270 | ValAcc: 0.8800 | ValLoss: 0.0401 \n",
      "\n",
      "[2017-12-02 05:12:40,486 INFO] Epoch: 271 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:40,778 INFO] Epoch: 271 | ValAcc: 0.8750 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:12:41,397 INFO] Epoch: 272 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:41,700 INFO] Epoch: 272 | ValAcc: 0.8850 | ValLoss: 0.0393 \n",
      "\n",
      "[2017-12-02 05:12:42,329 INFO] Epoch: 273 | TrainAcc: 1.0000 | TrainLoss: 0.0007\n",
      "[2017-12-02 05:12:42,624 INFO] Epoch: 273 | ValAcc: 0.8810 | ValLoss: 0.0394 \n",
      "\n",
      "[2017-12-02 05:12:43,246 INFO] Epoch: 274 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:43,539 INFO] Epoch: 274 | ValAcc: 0.8800 | ValLoss: 0.0393 \n",
      "\n",
      "[2017-12-02 05:12:44,172 INFO] Epoch: 275 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:44,468 INFO] Epoch: 275 | ValAcc: 0.8770 | ValLoss: 0.0393 \n",
      "\n",
      "[2017-12-02 05:12:45,096 INFO] Epoch: 276 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:45,395 INFO] Epoch: 276 | ValAcc: 0.8870 | ValLoss: 0.0392 \n",
      "\n",
      "[2017-12-02 05:12:46,004 INFO] Epoch: 277 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:46,303 INFO] Epoch: 277 | ValAcc: 0.8790 | ValLoss: 0.0393 \n",
      "\n",
      "[2017-12-02 05:12:46,909 INFO] Epoch: 278 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:47,194 INFO] Epoch: 278 | ValAcc: 0.8830 | ValLoss: 0.0395 \n",
      "\n",
      "[2017-12-02 05:12:47,808 INFO] Epoch: 279 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:48,102 INFO] Epoch: 279 | ValAcc: 0.8780 | ValLoss: 0.0399 \n",
      "\n",
      "[2017-12-02 05:12:48,718 INFO] Epoch: 280 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:12:49,026 INFO] Epoch: 280 | ValAcc: 0.8720 | ValLoss: 0.0402 \n",
      "\n",
      "[2017-12-02 05:12:49,668 INFO] Epoch: 281 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:49,966 INFO] Epoch: 281 | ValAcc: 0.8800 | ValLoss: 0.0397 \n",
      "\n",
      "[2017-12-02 05:12:50,585 INFO] Epoch: 282 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:12:50,883 INFO] Epoch: 282 | ValAcc: 0.8870 | ValLoss: 0.0387 \n",
      "\n",
      "[2017-12-02 05:12:51,499 INFO] Epoch: 283 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:12:51,790 INFO] Epoch: 283 | ValAcc: 0.8860 | ValLoss: 0.0399 \n",
      "\n",
      "[2017-12-02 05:12:52,423 INFO] Epoch: 284 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:52,713 INFO] Epoch: 284 | ValAcc: 0.8760 | ValLoss: 0.0397 \n",
      "\n",
      "[2017-12-02 05:12:53,320 INFO] Epoch: 285 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:12:53,612 INFO] Epoch: 285 | ValAcc: 0.8800 | ValLoss: 0.0392 \n",
      "\n",
      "[2017-12-02 05:12:54,217 INFO] Epoch: 286 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:12:54,509 INFO] Epoch: 286 | ValAcc: 0.8830 | ValLoss: 0.0395 \n",
      "\n",
      "[2017-12-02 05:12:55,125 INFO] Epoch: 287 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:12:55,427 INFO] Epoch: 287 | ValAcc: 0.8770 | ValLoss: 0.0407 \n",
      "\n",
      "[2017-12-02 05:12:56,043 INFO] Epoch: 288 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:12:56,348 INFO] Epoch: 288 | ValAcc: 0.8760 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:12:56,970 INFO] Epoch: 289 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:12:57,259 INFO] Epoch: 289 | ValAcc: 0.8800 | ValLoss: 0.0407 \n",
      "\n",
      "[2017-12-02 05:12:57,872 INFO] Epoch: 290 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:12:58,170 INFO] Epoch: 290 | ValAcc: 0.8790 | ValLoss: 0.0396 \n",
      "\n",
      "[2017-12-02 05:12:58,801 INFO] Epoch: 291 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:12:59,089 INFO] Epoch: 291 | ValAcc: 0.8780 | ValLoss: 0.0393 \n",
      "\n",
      "[2017-12-02 05:12:59,707 INFO] Epoch: 292 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:00,001 INFO] Epoch: 292 | ValAcc: 0.8760 | ValLoss: 0.0395 \n",
      "\n",
      "[2017-12-02 05:13:00,627 INFO] Epoch: 293 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:00,918 INFO] Epoch: 293 | ValAcc: 0.8790 | ValLoss: 0.0396 \n",
      "\n",
      "[2017-12-02 05:13:01,548 INFO] Epoch: 294 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:01,845 INFO] Epoch: 294 | ValAcc: 0.8780 | ValLoss: 0.0396 \n",
      "\n",
      "[2017-12-02 05:13:02,482 INFO] Epoch: 295 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:02,779 INFO] Epoch: 295 | ValAcc: 0.8720 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:13:03,401 INFO] Epoch: 296 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:03,698 INFO] Epoch: 296 | ValAcc: 0.8800 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:13:04,324 INFO] Epoch: 297 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:04,628 INFO] Epoch: 297 | ValAcc: 0.8780 | ValLoss: 0.0405 \n",
      "\n",
      "[2017-12-02 05:13:05,248 INFO] Epoch: 298 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:05,542 INFO] Epoch: 298 | ValAcc: 0.8850 | ValLoss: 0.0389 \n",
      "\n",
      "[2017-12-02 05:13:06,149 INFO] Epoch: 299 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:06,439 INFO] Epoch: 299 | ValAcc: 0.8760 | ValLoss: 0.0396 \n",
      "\n",
      "[2017-12-02 05:13:07,045 INFO] Epoch: 300 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:07,334 INFO] Epoch: 300 | ValAcc: 0.8730 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:13:07,966 INFO] Epoch: 301 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:08,263 INFO] Epoch: 301 | ValAcc: 0.8710 | ValLoss: 0.0399 \n",
      "\n",
      "[2017-12-02 05:13:08,876 INFO] Epoch: 302 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:13:09,183 INFO] Epoch: 302 | ValAcc: 0.8770 | ValLoss: 0.0392 \n",
      "\n",
      "[2017-12-02 05:13:09,850 INFO] Epoch: 303 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:10,144 INFO] Epoch: 303 | ValAcc: 0.8780 | ValLoss: 0.0406 \n",
      "\n",
      "[2017-12-02 05:13:10,780 INFO] Epoch: 304 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:11,070 INFO] Epoch: 304 | ValAcc: 0.8710 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:13:11,718 INFO] Epoch: 305 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:12,015 INFO] Epoch: 305 | ValAcc: 0.8800 | ValLoss: 0.0396 \n",
      "\n",
      "[2017-12-02 05:13:12,657 INFO] Epoch: 306 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:12,947 INFO] Epoch: 306 | ValAcc: 0.8810 | ValLoss: 0.0395 \n",
      "\n",
      "[2017-12-02 05:13:13,549 INFO] Epoch: 307 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:13,848 INFO] Epoch: 307 | ValAcc: 0.8820 | ValLoss: 0.0397 \n",
      "\n",
      "[2017-12-02 05:13:14,476 INFO] Epoch: 308 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:14,777 INFO] Epoch: 308 | ValAcc: 0.8820 | ValLoss: 0.0396 \n",
      "\n",
      "[2017-12-02 05:13:15,415 INFO] Epoch: 309 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:15,721 INFO] Epoch: 309 | ValAcc: 0.8820 | ValLoss: 0.0394 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:13:16,352 INFO] Epoch: 310 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:16,671 INFO] Epoch: 310 | ValAcc: 0.8670 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:13:17,327 INFO] Epoch: 311 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:17,679 INFO] Epoch: 311 | ValAcc: 0.8770 | ValLoss: 0.0394 \n",
      "\n",
      "[2017-12-02 05:13:18,432 INFO] Epoch: 312 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:18,776 INFO] Epoch: 312 | ValAcc: 0.8820 | ValLoss: 0.0390 \n",
      "\n",
      "[2017-12-02 05:13:19,536 INFO] Epoch: 313 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:19,914 INFO] Epoch: 313 | ValAcc: 0.8780 | ValLoss: 0.0403 \n",
      "\n",
      "[2017-12-02 05:13:20,660 INFO] Epoch: 314 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:20,997 INFO] Epoch: 314 | ValAcc: 0.8800 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:13:21,670 INFO] Epoch: 315 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:21,991 INFO] Epoch: 315 | ValAcc: 0.8880 | ValLoss: 0.0398 \n",
      "\n",
      "[2017-12-02 05:13:22,660 INFO] Epoch: 316 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:22,952 INFO] Epoch: 316 | ValAcc: 0.8810 | ValLoss: 0.0400 \n",
      "\n",
      "[2017-12-02 05:13:23,574 INFO] Epoch: 317 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:23,901 INFO] Epoch: 317 | ValAcc: 0.8810 | ValLoss: 0.0394 \n",
      "\n",
      "[2017-12-02 05:13:24,564 INFO] Epoch: 318 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:24,887 INFO] Epoch: 318 | ValAcc: 0.8770 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:13:25,546 INFO] Epoch: 319 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:25,873 INFO] Epoch: 319 | ValAcc: 0.8740 | ValLoss: 0.0402 \n",
      "\n",
      "[2017-12-02 05:13:26,527 INFO] Epoch: 320 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:26,830 INFO] Epoch: 320 | ValAcc: 0.8820 | ValLoss: 0.0400 \n",
      "\n",
      "[2017-12-02 05:13:27,503 INFO] Epoch: 321 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:27,844 INFO] Epoch: 321 | ValAcc: 0.8730 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:13:28,571 INFO] Epoch: 322 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:13:28,875 INFO] Epoch: 322 | ValAcc: 0.8460 | ValLoss: 0.0489 \n",
      "\n",
      "[2017-12-02 05:13:29,624 INFO] Epoch: 323 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:13:30,003 INFO] Epoch: 323 | ValAcc: 0.8700 | ValLoss: 0.0467 \n",
      "\n",
      "[2017-12-02 05:13:30,741 INFO] Epoch: 324 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:31,099 INFO] Epoch: 324 | ValAcc: 0.8760 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:13:31,863 INFO] Epoch: 325 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:32,163 INFO] Epoch: 325 | ValAcc: 0.8670 | ValLoss: 0.0452 \n",
      "\n",
      "[2017-12-02 05:13:32,881 INFO] Epoch: 326 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:33,227 INFO] Epoch: 326 | ValAcc: 0.8750 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:13:33,941 INFO] Epoch: 327 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:34,303 INFO] Epoch: 327 | ValAcc: 0.8710 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:13:35,109 INFO] Epoch: 328 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:35,442 INFO] Epoch: 328 | ValAcc: 0.8670 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:13:36,098 INFO] Epoch: 329 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:36,400 INFO] Epoch: 329 | ValAcc: 0.8660 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:13:37,018 INFO] Epoch: 330 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:37,312 INFO] Epoch: 330 | ValAcc: 0.8810 | ValLoss: 0.0399 \n",
      "\n",
      "[2017-12-02 05:13:37,933 INFO] Epoch: 331 | TrainAcc: 1.0000 | TrainLoss: 0.0006\n",
      "[2017-12-02 05:13:38,233 INFO] Epoch: 331 | ValAcc: 0.8730 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:13:38,863 INFO] Epoch: 332 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:39,164 INFO] Epoch: 332 | ValAcc: 0.8710 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:13:39,816 INFO] Epoch: 333 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:40,112 INFO] Epoch: 333 | ValAcc: 0.8810 | ValLoss: 0.0408 \n",
      "\n",
      "[2017-12-02 05:13:40,749 INFO] Epoch: 334 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:41,043 INFO] Epoch: 334 | ValAcc: 0.8610 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:13:41,678 INFO] Epoch: 335 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:41,974 INFO] Epoch: 335 | ValAcc: 0.8660 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:13:42,599 INFO] Epoch: 336 | TrainAcc: 1.0000 | TrainLoss: 0.0005\n",
      "[2017-12-02 05:13:42,922 INFO] Epoch: 336 | ValAcc: 0.8840 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:13:43,540 INFO] Epoch: 337 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:43,839 INFO] Epoch: 337 | ValAcc: 0.8760 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:13:44,484 INFO] Epoch: 338 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:44,789 INFO] Epoch: 338 | ValAcc: 0.8780 | ValLoss: 0.0400 \n",
      "\n",
      "[2017-12-02 05:13:45,429 INFO] Epoch: 339 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:45,719 INFO] Epoch: 339 | ValAcc: 0.8850 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:13:46,341 INFO] Epoch: 340 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:46,640 INFO] Epoch: 340 | ValAcc: 0.8740 | ValLoss: 0.0401 \n",
      "\n",
      "[2017-12-02 05:13:47,269 INFO] Epoch: 341 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:47,581 INFO] Epoch: 341 | ValAcc: 0.8700 | ValLoss: 0.0406 \n",
      "\n",
      "[2017-12-02 05:13:48,214 INFO] Epoch: 342 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:48,521 INFO] Epoch: 342 | ValAcc: 0.8820 | ValLoss: 0.0396 \n",
      "\n",
      "[2017-12-02 05:13:49,173 INFO] Epoch: 343 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:49,469 INFO] Epoch: 343 | ValAcc: 0.8680 | ValLoss: 0.0407 \n",
      "\n",
      "[2017-12-02 05:13:50,078 INFO] Epoch: 344 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:50,374 INFO] Epoch: 344 | ValAcc: 0.8700 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:13:50,999 INFO] Epoch: 345 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:51,296 INFO] Epoch: 345 | ValAcc: 0.8780 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:13:51,933 INFO] Epoch: 346 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:52,232 INFO] Epoch: 346 | ValAcc: 0.8790 | ValLoss: 0.0403 \n",
      "\n",
      "[2017-12-02 05:13:52,869 INFO] Epoch: 347 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:53,177 INFO] Epoch: 347 | ValAcc: 0.8800 | ValLoss: 0.0407 \n",
      "\n",
      "[2017-12-02 05:13:53,797 INFO] Epoch: 348 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:54,088 INFO] Epoch: 348 | ValAcc: 0.8780 | ValLoss: 0.0409 \n",
      "\n",
      "[2017-12-02 05:13:54,694 INFO] Epoch: 349 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:54,988 INFO] Epoch: 349 | ValAcc: 0.8820 | ValLoss: 0.0392 \n",
      "\n",
      "[2017-12-02 05:13:55,614 INFO] Epoch: 350 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:55,909 INFO] Epoch: 350 | ValAcc: 0.8790 | ValLoss: 0.0395 \n",
      "\n",
      "[2017-12-02 05:13:56,523 INFO] Epoch: 351 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:56,819 INFO] Epoch: 351 | ValAcc: 0.8750 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:13:57,433 INFO] Epoch: 352 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:57,730 INFO] Epoch: 352 | ValAcc: 0.8820 | ValLoss: 0.0405 \n",
      "\n",
      "[2017-12-02 05:13:58,366 INFO] Epoch: 353 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:58,665 INFO] Epoch: 353 | ValAcc: 0.8840 | ValLoss: 0.0400 \n",
      "\n",
      "[2017-12-02 05:13:59,286 INFO] Epoch: 354 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:13:59,599 INFO] Epoch: 354 | ValAcc: 0.8780 | ValLoss: 0.0398 \n",
      "\n",
      "[2017-12-02 05:14:00,220 INFO] Epoch: 355 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:00,513 INFO] Epoch: 355 | ValAcc: 0.8740 | ValLoss: 0.0398 \n",
      "\n",
      "[2017-12-02 05:14:01,137 INFO] Epoch: 356 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:01,438 INFO] Epoch: 356 | ValAcc: 0.8810 | ValLoss: 0.0396 \n",
      "\n",
      "[2017-12-02 05:14:02,071 INFO] Epoch: 357 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:02,365 INFO] Epoch: 357 | ValAcc: 0.8780 | ValLoss: 0.0402 \n",
      "\n",
      "[2017-12-02 05:14:02,998 INFO] Epoch: 358 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:03,297 INFO] Epoch: 358 | ValAcc: 0.8800 | ValLoss: 0.0396 \n",
      "\n",
      "[2017-12-02 05:14:03,932 INFO] Epoch: 359 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:04,223 INFO] Epoch: 359 | ValAcc: 0.8760 | ValLoss: 0.0403 \n",
      "\n",
      "[2017-12-02 05:14:04,844 INFO] Epoch: 360 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:05,138 INFO] Epoch: 360 | ValAcc: 0.8790 | ValLoss: 0.0399 \n",
      "\n",
      "[2017-12-02 05:14:05,750 INFO] Epoch: 361 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:14:06,051 INFO] Epoch: 361 | ValAcc: 0.8780 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:14:06,667 INFO] Epoch: 362 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:06,967 INFO] Epoch: 362 | ValAcc: 0.8650 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:14:07,603 INFO] Epoch: 363 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:07,899 INFO] Epoch: 363 | ValAcc: 0.8800 | ValLoss: 0.0401 \n",
      "\n",
      "[2017-12-02 05:14:08,516 INFO] Epoch: 364 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:08,808 INFO] Epoch: 364 | ValAcc: 0.8800 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:14:09,422 INFO] Epoch: 365 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:09,722 INFO] Epoch: 365 | ValAcc: 0.8810 | ValLoss: 0.0402 \n",
      "\n",
      "[2017-12-02 05:14:10,340 INFO] Epoch: 366 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:10,656 INFO] Epoch: 366 | ValAcc: 0.8840 | ValLoss: 0.0400 \n",
      "\n",
      "[2017-12-02 05:14:11,281 INFO] Epoch: 367 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:11,575 INFO] Epoch: 367 | ValAcc: 0.8840 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:14:12,192 INFO] Epoch: 368 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:12,483 INFO] Epoch: 368 | ValAcc: 0.8760 | ValLoss: 0.0418 \n",
      "\n",
      "[2017-12-02 05:14:13,107 INFO] Epoch: 369 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:13,404 INFO] Epoch: 369 | ValAcc: 0.8800 | ValLoss: 0.0406 \n",
      "\n",
      "[2017-12-02 05:14:14,024 INFO] Epoch: 370 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:14,314 INFO] Epoch: 370 | ValAcc: 0.8700 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:14:14,944 INFO] Epoch: 371 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:15,242 INFO] Epoch: 371 | ValAcc: 0.8720 | ValLoss: 0.0409 \n",
      "\n",
      "[2017-12-02 05:14:15,849 INFO] Epoch: 372 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:16,137 INFO] Epoch: 372 | ValAcc: 0.8880 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:14:16,766 INFO] Epoch: 373 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:17,062 INFO] Epoch: 373 | ValAcc: 0.8780 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:14:17,681 INFO] Epoch: 374 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:17,976 INFO] Epoch: 374 | ValAcc: 0.8740 | ValLoss: 0.0406 \n",
      "\n",
      "[2017-12-02 05:14:18,600 INFO] Epoch: 375 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:18,888 INFO] Epoch: 375 | ValAcc: 0.8770 | ValLoss: 0.0405 \n",
      "\n",
      "[2017-12-02 05:14:19,528 INFO] Epoch: 376 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:19,834 INFO] Epoch: 376 | ValAcc: 0.8760 | ValLoss: 0.0403 \n",
      "\n",
      "[2017-12-02 05:14:20,459 INFO] Epoch: 377 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:20,752 INFO] Epoch: 377 | ValAcc: 0.8870 | ValLoss: 0.0400 \n",
      "\n",
      "[2017-12-02 05:14:21,373 INFO] Epoch: 378 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:21,670 INFO] Epoch: 378 | ValAcc: 0.8800 | ValLoss: 0.0406 \n",
      "\n",
      "[2017-12-02 05:14:22,280 INFO] Epoch: 379 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:22,580 INFO] Epoch: 379 | ValAcc: 0.8780 | ValLoss: 0.0408 \n",
      "\n",
      "[2017-12-02 05:14:23,205 INFO] Epoch: 380 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:23,504 INFO] Epoch: 380 | ValAcc: 0.8760 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:14:24,110 INFO] Epoch: 381 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:24,405 INFO] Epoch: 381 | ValAcc: 0.8790 | ValLoss: 0.0402 \n",
      "\n",
      "[2017-12-02 05:14:25,002 INFO] Epoch: 382 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:25,293 INFO] Epoch: 382 | ValAcc: 0.8780 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:14:25,918 INFO] Epoch: 383 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:26,224 INFO] Epoch: 383 | ValAcc: 0.8850 | ValLoss: 0.0401 \n",
      "\n",
      "[2017-12-02 05:14:26,844 INFO] Epoch: 384 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:27,134 INFO] Epoch: 384 | ValAcc: 0.8740 | ValLoss: 0.0405 \n",
      "\n",
      "[2017-12-02 05:14:27,736 INFO] Epoch: 385 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:28,028 INFO] Epoch: 385 | ValAcc: 0.8700 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:14:28,650 INFO] Epoch: 386 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:28,950 INFO] Epoch: 386 | ValAcc: 0.8790 | ValLoss: 0.0407 \n",
      "\n",
      "[2017-12-02 05:14:29,564 INFO] Epoch: 387 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:29,860 INFO] Epoch: 387 | ValAcc: 0.8690 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:14:30,479 INFO] Epoch: 388 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:30,771 INFO] Epoch: 388 | ValAcc: 0.8740 | ValLoss: 0.0418 \n",
      "\n",
      "[2017-12-02 05:14:31,391 INFO] Epoch: 389 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:31,688 INFO] Epoch: 389 | ValAcc: 0.8760 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:14:32,316 INFO] Epoch: 390 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:32,611 INFO] Epoch: 390 | ValAcc: 0.8890 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:14:33,240 INFO] Epoch: 391 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:33,560 INFO] Epoch: 391 | ValAcc: 0.8850 | ValLoss: 0.0402 \n",
      "\n",
      "[2017-12-02 05:14:34,184 INFO] Epoch: 392 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:34,478 INFO] Epoch: 392 | ValAcc: 0.8810 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:14:35,104 INFO] Epoch: 393 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:35,402 INFO] Epoch: 393 | ValAcc: 0.8580 | ValLoss: 0.0467 \n",
      "\n",
      "[2017-12-02 05:14:36,018 INFO] Epoch: 394 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:36,317 INFO] Epoch: 394 | ValAcc: 0.8700 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:14:36,943 INFO] Epoch: 395 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:37,248 INFO] Epoch: 395 | ValAcc: 0.8820 | ValLoss: 0.0406 \n",
      "\n",
      "[2017-12-02 05:14:37,879 INFO] Epoch: 396 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:38,183 INFO] Epoch: 396 | ValAcc: 0.8800 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:14:38,802 INFO] Epoch: 397 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:39,096 INFO] Epoch: 397 | ValAcc: 0.8760 | ValLoss: 0.0408 \n",
      "\n",
      "[2017-12-02 05:14:39,727 INFO] Epoch: 398 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:40,019 INFO] Epoch: 398 | ValAcc: 0.8710 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:14:40,651 INFO] Epoch: 399 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:40,940 INFO] Epoch: 399 | ValAcc: 0.8750 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:14:41,547 INFO] Epoch: 400 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:41,837 INFO] Epoch: 400 | ValAcc: 0.8770 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:14:42,450 INFO] Epoch: 401 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:42,755 INFO] Epoch: 401 | ValAcc: 0.8810 | ValLoss: 0.0405 \n",
      "\n",
      "[2017-12-02 05:14:43,383 INFO] Epoch: 402 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:43,685 INFO] Epoch: 402 | ValAcc: 0.8690 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:14:44,303 INFO] Epoch: 403 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:44,598 INFO] Epoch: 403 | ValAcc: 0.8720 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:14:45,215 INFO] Epoch: 404 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:45,523 INFO] Epoch: 404 | ValAcc: 0.8820 | ValLoss: 0.0399 \n",
      "\n",
      "[2017-12-02 05:14:46,128 INFO] Epoch: 405 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:46,424 INFO] Epoch: 405 | ValAcc: 0.8800 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:14:47,046 INFO] Epoch: 406 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:47,348 INFO] Epoch: 406 | ValAcc: 0.8780 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:14:47,958 INFO] Epoch: 407 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:48,254 INFO] Epoch: 407 | ValAcc: 0.8780 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:14:48,881 INFO] Epoch: 408 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:49,185 INFO] Epoch: 408 | ValAcc: 0.8800 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:14:49,797 INFO] Epoch: 409 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:50,086 INFO] Epoch: 409 | ValAcc: 0.8820 | ValLoss: 0.0408 \n",
      "\n",
      "[2017-12-02 05:14:50,690 INFO] Epoch: 410 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:50,980 INFO] Epoch: 410 | ValAcc: 0.8840 | ValLoss: 0.0402 \n",
      "\n",
      "[2017-12-02 05:14:51,594 INFO] Epoch: 411 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:51,884 INFO] Epoch: 411 | ValAcc: 0.8790 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:14:52,486 INFO] Epoch: 412 | TrainAcc: 1.0000 | TrainLoss: 0.0004\n",
      "[2017-12-02 05:14:52,778 INFO] Epoch: 412 | ValAcc: 0.8670 | ValLoss: 0.0444 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:14:53,397 INFO] Epoch: 413 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:53,705 INFO] Epoch: 413 | ValAcc: 0.8830 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:14:54,319 INFO] Epoch: 414 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:54,617 INFO] Epoch: 414 | ValAcc: 0.8820 | ValLoss: 0.0405 \n",
      "\n",
      "[2017-12-02 05:14:55,249 INFO] Epoch: 415 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:55,556 INFO] Epoch: 415 | ValAcc: 0.8770 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:14:56,184 INFO] Epoch: 416 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:56,472 INFO] Epoch: 416 | ValAcc: 0.8840 | ValLoss: 0.0408 \n",
      "\n",
      "[2017-12-02 05:14:57,087 INFO] Epoch: 417 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:57,377 INFO] Epoch: 417 | ValAcc: 0.8780 | ValLoss: 0.0405 \n",
      "\n",
      "[2017-12-02 05:14:57,978 INFO] Epoch: 418 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:58,273 INFO] Epoch: 418 | ValAcc: 0.8740 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:14:58,883 INFO] Epoch: 419 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:14:59,178 INFO] Epoch: 419 | ValAcc: 0.8750 | ValLoss: 0.0406 \n",
      "\n",
      "[2017-12-02 05:14:59,792 INFO] Epoch: 420 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:00,089 INFO] Epoch: 420 | ValAcc: 0.8790 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:15:00,700 INFO] Epoch: 421 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:00,990 INFO] Epoch: 421 | ValAcc: 0.8790 | ValLoss: 0.0408 \n",
      "\n",
      "[2017-12-02 05:15:01,616 INFO] Epoch: 422 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:01,914 INFO] Epoch: 422 | ValAcc: 0.8840 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:15:02,543 INFO] Epoch: 423 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:02,845 INFO] Epoch: 423 | ValAcc: 0.8800 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:15:03,467 INFO] Epoch: 424 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:03,780 INFO] Epoch: 424 | ValAcc: 0.8760 | ValLoss: 0.0405 \n",
      "\n",
      "[2017-12-02 05:15:04,393 INFO] Epoch: 425 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:04,694 INFO] Epoch: 425 | ValAcc: 0.8830 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:15:05,307 INFO] Epoch: 426 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:05,611 INFO] Epoch: 426 | ValAcc: 0.8790 | ValLoss: 0.0406 \n",
      "\n",
      "[2017-12-02 05:15:06,238 INFO] Epoch: 427 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:06,532 INFO] Epoch: 427 | ValAcc: 0.8780 | ValLoss: 0.0405 \n",
      "\n",
      "[2017-12-02 05:15:07,138 INFO] Epoch: 428 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:07,439 INFO] Epoch: 428 | ValAcc: 0.8840 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:15:08,061 INFO] Epoch: 429 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:08,356 INFO] Epoch: 429 | ValAcc: 0.8770 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:15:08,977 INFO] Epoch: 430 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:09,306 INFO] Epoch: 430 | ValAcc: 0.8710 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:15:09,937 INFO] Epoch: 431 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:10,233 INFO] Epoch: 431 | ValAcc: 0.8790 | ValLoss: 0.0406 \n",
      "\n",
      "[2017-12-02 05:15:10,878 INFO] Epoch: 432 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:11,180 INFO] Epoch: 432 | ValAcc: 0.8720 | ValLoss: 0.0407 \n",
      "\n",
      "[2017-12-02 05:15:11,806 INFO] Epoch: 433 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:12,099 INFO] Epoch: 433 | ValAcc: 0.8760 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:15:12,729 INFO] Epoch: 434 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:13,033 INFO] Epoch: 434 | ValAcc: 0.8720 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:15:13,661 INFO] Epoch: 435 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:13,962 INFO] Epoch: 435 | ValAcc: 0.8730 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:15:14,587 INFO] Epoch: 436 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:14,890 INFO] Epoch: 436 | ValAcc: 0.8750 | ValLoss: 0.0409 \n",
      "\n",
      "[2017-12-02 05:15:15,517 INFO] Epoch: 437 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:15,811 INFO] Epoch: 437 | ValAcc: 0.8840 | ValLoss: 0.0402 \n",
      "\n",
      "[2017-12-02 05:15:16,439 INFO] Epoch: 438 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:16,743 INFO] Epoch: 438 | ValAcc: 0.8850 | ValLoss: 0.0400 \n",
      "\n",
      "[2017-12-02 05:15:17,347 INFO] Epoch: 439 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:17,645 INFO] Epoch: 439 | ValAcc: 0.8810 | ValLoss: 0.0405 \n",
      "\n",
      "[2017-12-02 05:15:18,262 INFO] Epoch: 440 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:18,554 INFO] Epoch: 440 | ValAcc: 0.8770 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:15:19,185 INFO] Epoch: 441 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:19,484 INFO] Epoch: 441 | ValAcc: 0.8770 | ValLoss: 0.0405 \n",
      "\n",
      "[2017-12-02 05:15:20,110 INFO] Epoch: 442 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:20,407 INFO] Epoch: 442 | ValAcc: 0.8790 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:15:21,027 INFO] Epoch: 443 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:21,328 INFO] Epoch: 443 | ValAcc: 0.8740 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:15:21,960 INFO] Epoch: 444 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:22,259 INFO] Epoch: 444 | ValAcc: 0.8780 | ValLoss: 0.0407 \n",
      "\n",
      "[2017-12-02 05:15:22,890 INFO] Epoch: 445 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:23,179 INFO] Epoch: 445 | ValAcc: 0.8780 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:15:23,806 INFO] Epoch: 446 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:24,110 INFO] Epoch: 446 | ValAcc: 0.8750 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:15:24,723 INFO] Epoch: 447 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:25,021 INFO] Epoch: 447 | ValAcc: 0.8880 | ValLoss: 0.0406 \n",
      "\n",
      "[2017-12-02 05:15:25,656 INFO] Epoch: 448 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:25,951 INFO] Epoch: 448 | ValAcc: 0.8810 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:15:26,565 INFO] Epoch: 449 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:26,854 INFO] Epoch: 449 | ValAcc: 0.8770 | ValLoss: 0.0408 \n",
      "\n",
      "[2017-12-02 05:15:27,483 INFO] Epoch: 450 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:27,778 INFO] Epoch: 450 | ValAcc: 0.8760 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:15:28,395 INFO] Epoch: 451 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:28,686 INFO] Epoch: 451 | ValAcc: 0.8740 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:15:29,327 INFO] Epoch: 452 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:29,622 INFO] Epoch: 452 | ValAcc: 0.8810 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:15:30,258 INFO] Epoch: 453 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:30,550 INFO] Epoch: 453 | ValAcc: 0.8800 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:15:31,162 INFO] Epoch: 454 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:31,455 INFO] Epoch: 454 | ValAcc: 0.8820 | ValLoss: 0.0404 \n",
      "\n",
      "[2017-12-02 05:15:32,079 INFO] Epoch: 455 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:32,373 INFO] Epoch: 455 | ValAcc: 0.8770 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:15:33,009 INFO] Epoch: 456 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:33,306 INFO] Epoch: 456 | ValAcc: 0.8800 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:15:33,928 INFO] Epoch: 457 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:34,224 INFO] Epoch: 457 | ValAcc: 0.8770 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:15:34,853 INFO] Epoch: 458 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:35,149 INFO] Epoch: 458 | ValAcc: 0.8740 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:15:35,763 INFO] Epoch: 459 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:36,060 INFO] Epoch: 459 | ValAcc: 0.8790 | ValLoss: 0.0409 \n",
      "\n",
      "[2017-12-02 05:15:36,692 INFO] Epoch: 460 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:36,983 INFO] Epoch: 460 | ValAcc: 0.8850 | ValLoss: 0.0401 \n",
      "\n",
      "[2017-12-02 05:15:37,601 INFO] Epoch: 461 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:37,890 INFO] Epoch: 461 | ValAcc: 0.8780 | ValLoss: 0.0406 \n",
      "\n",
      "[2017-12-02 05:15:38,493 INFO] Epoch: 462 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:38,788 INFO] Epoch: 462 | ValAcc: 0.8790 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:15:39,408 INFO] Epoch: 463 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:39,707 INFO] Epoch: 463 | ValAcc: 0.8800 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:15:40,426 INFO] Epoch: 464 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:15:40,743 INFO] Epoch: 464 | ValAcc: 0.8740 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:15:41,418 INFO] Epoch: 465 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:41,763 INFO] Epoch: 465 | ValAcc: 0.8770 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:15:42,420 INFO] Epoch: 466 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:42,792 INFO] Epoch: 466 | ValAcc: 0.8750 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:15:43,444 INFO] Epoch: 467 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:43,740 INFO] Epoch: 467 | ValAcc: 0.8820 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:15:44,376 INFO] Epoch: 468 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:44,667 INFO] Epoch: 468 | ValAcc: 0.8720 | ValLoss: 0.0454 \n",
      "\n",
      "[2017-12-02 05:15:45,290 INFO] Epoch: 469 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:45,585 INFO] Epoch: 469 | ValAcc: 0.8710 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:15:46,210 INFO] Epoch: 470 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:46,499 INFO] Epoch: 470 | ValAcc: 0.8710 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:15:47,114 INFO] Epoch: 471 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:47,414 INFO] Epoch: 471 | ValAcc: 0.8750 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:15:48,020 INFO] Epoch: 472 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:15:48,311 INFO] Epoch: 472 | ValAcc: 0.8800 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:15:48,922 INFO] Epoch: 473 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:49,233 INFO] Epoch: 473 | ValAcc: 0.8840 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:15:49,857 INFO] Epoch: 474 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:50,152 INFO] Epoch: 474 | ValAcc: 0.8800 | ValLoss: 0.0406 \n",
      "\n",
      "[2017-12-02 05:15:50,770 INFO] Epoch: 475 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:51,068 INFO] Epoch: 475 | ValAcc: 0.8780 | ValLoss: 0.0406 \n",
      "\n",
      "[2017-12-02 05:15:51,693 INFO] Epoch: 476 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:15:51,992 INFO] Epoch: 476 | ValAcc: 0.8820 | ValLoss: 0.0407 \n",
      "\n",
      "[2017-12-02 05:15:52,609 INFO] Epoch: 477 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:52,905 INFO] Epoch: 477 | ValAcc: 0.8830 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:15:53,537 INFO] Epoch: 478 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:15:53,834 INFO] Epoch: 478 | ValAcc: 0.8720 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:15:54,450 INFO] Epoch: 479 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:15:54,741 INFO] Epoch: 479 | ValAcc: 0.8770 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:15:55,371 INFO] Epoch: 480 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:15:55,667 INFO] Epoch: 480 | ValAcc: 0.8760 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:15:56,292 INFO] Epoch: 481 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:56,592 INFO] Epoch: 481 | ValAcc: 0.8770 | ValLoss: 0.0407 \n",
      "\n",
      "[2017-12-02 05:15:57,209 INFO] Epoch: 482 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:57,506 INFO] Epoch: 482 | ValAcc: 0.8900 | ValLoss: 0.0409 \n",
      "\n",
      "[2017-12-02 05:15:58,128 INFO] Epoch: 483 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:15:58,429 INFO] Epoch: 483 | ValAcc: 0.8720 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:15:59,046 INFO] Epoch: 484 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:15:59,340 INFO] Epoch: 484 | ValAcc: 0.8760 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:15:59,971 INFO] Epoch: 485 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:00,267 INFO] Epoch: 485 | ValAcc: 0.8800 | ValLoss: 0.0406 \n",
      "\n",
      "[2017-12-02 05:16:00,897 INFO] Epoch: 486 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:01,197 INFO] Epoch: 486 | ValAcc: 0.8730 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:16:01,827 INFO] Epoch: 487 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:02,124 INFO] Epoch: 487 | ValAcc: 0.8760 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:16:02,752 INFO] Epoch: 488 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:03,047 INFO] Epoch: 488 | ValAcc: 0.8820 | ValLoss: 0.0405 \n",
      "\n",
      "[2017-12-02 05:16:03,676 INFO] Epoch: 489 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:03,972 INFO] Epoch: 489 | ValAcc: 0.8810 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:16:04,607 INFO] Epoch: 490 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:04,903 INFO] Epoch: 490 | ValAcc: 0.8810 | ValLoss: 0.0409 \n",
      "\n",
      "[2017-12-02 05:16:05,511 INFO] Epoch: 491 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:05,813 INFO] Epoch: 491 | ValAcc: 0.8750 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:16:06,437 INFO] Epoch: 492 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:06,729 INFO] Epoch: 492 | ValAcc: 0.8820 | ValLoss: 0.0407 \n",
      "\n",
      "[2017-12-02 05:16:07,352 INFO] Epoch: 493 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:07,644 INFO] Epoch: 493 | ValAcc: 0.8850 | ValLoss: 0.0405 \n",
      "\n",
      "[2017-12-02 05:16:08,261 INFO] Epoch: 494 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:08,556 INFO] Epoch: 494 | ValAcc: 0.8790 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:16:09,182 INFO] Epoch: 495 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:09,480 INFO] Epoch: 495 | ValAcc: 0.8820 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:16:10,108 INFO] Epoch: 496 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:10,412 INFO] Epoch: 496 | ValAcc: 0.8760 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:16:11,044 INFO] Epoch: 497 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:11,338 INFO] Epoch: 497 | ValAcc: 0.8770 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:16:11,953 INFO] Epoch: 498 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:12,249 INFO] Epoch: 498 | ValAcc: 0.8770 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:16:12,878 INFO] Epoch: 499 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:13,170 INFO] Epoch: 499 | ValAcc: 0.8760 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:16:13,783 INFO] Epoch: 500 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:14,074 INFO] Epoch: 500 | ValAcc: 0.8770 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:16:14,697 INFO] Epoch: 501 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:14,996 INFO] Epoch: 501 | ValAcc: 0.8870 | ValLoss: 0.0408 \n",
      "\n",
      "[2017-12-02 05:16:15,603 INFO] Epoch: 502 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:15,898 INFO] Epoch: 502 | ValAcc: 0.8880 | ValLoss: 0.0409 \n",
      "\n",
      "[2017-12-02 05:16:16,528 INFO] Epoch: 503 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:16,825 INFO] Epoch: 503 | ValAcc: 0.8730 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:16:17,445 INFO] Epoch: 504 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:17,739 INFO] Epoch: 504 | ValAcc: 0.8780 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:16:18,359 INFO] Epoch: 505 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:18,665 INFO] Epoch: 505 | ValAcc: 0.8790 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:16:19,293 INFO] Epoch: 506 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:19,595 INFO] Epoch: 506 | ValAcc: 0.8820 | ValLoss: 0.0409 \n",
      "\n",
      "[2017-12-02 05:16:20,217 INFO] Epoch: 507 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:20,526 INFO] Epoch: 507 | ValAcc: 0.8790 | ValLoss: 0.0420 \n",
      "\n",
      "[2017-12-02 05:16:21,154 INFO] Epoch: 508 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:21,451 INFO] Epoch: 508 | ValAcc: 0.8700 | ValLoss: 0.0443 \n",
      "\n",
      "[2017-12-02 05:16:22,073 INFO] Epoch: 509 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:22,383 INFO] Epoch: 509 | ValAcc: 0.8880 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:16:23,000 INFO] Epoch: 510 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:23,296 INFO] Epoch: 510 | ValAcc: 0.8800 | ValLoss: 0.0406 \n",
      "\n",
      "[2017-12-02 05:16:23,915 INFO] Epoch: 511 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:24,226 INFO] Epoch: 511 | ValAcc: 0.8800 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:16:24,847 INFO] Epoch: 512 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:25,141 INFO] Epoch: 512 | ValAcc: 0.8800 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:16:25,762 INFO] Epoch: 513 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:26,056 INFO] Epoch: 513 | ValAcc: 0.8780 | ValLoss: 0.0408 \n",
      "\n",
      "[2017-12-02 05:16:26,663 INFO] Epoch: 514 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:26,955 INFO] Epoch: 514 | ValAcc: 0.8810 | ValLoss: 0.0409 \n",
      "\n",
      "[2017-12-02 05:16:27,566 INFO] Epoch: 515 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:27,860 INFO] Epoch: 515 | ValAcc: 0.8790 | ValLoss: 0.0416 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:16:28,487 INFO] Epoch: 516 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:28,784 INFO] Epoch: 516 | ValAcc: 0.8780 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:16:29,407 INFO] Epoch: 517 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:29,707 INFO] Epoch: 517 | ValAcc: 0.8790 | ValLoss: 0.0418 \n",
      "\n",
      "[2017-12-02 05:16:30,324 INFO] Epoch: 518 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:30,622 INFO] Epoch: 518 | ValAcc: 0.8790 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:16:31,226 INFO] Epoch: 519 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:31,521 INFO] Epoch: 519 | ValAcc: 0.8720 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:16:32,146 INFO] Epoch: 520 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:32,445 INFO] Epoch: 520 | ValAcc: 0.8750 | ValLoss: 0.0418 \n",
      "\n",
      "[2017-12-02 05:16:33,048 INFO] Epoch: 521 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:33,339 INFO] Epoch: 521 | ValAcc: 0.8790 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:16:33,963 INFO] Epoch: 522 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:34,259 INFO] Epoch: 522 | ValAcc: 0.8840 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:16:34,885 INFO] Epoch: 523 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:35,173 INFO] Epoch: 523 | ValAcc: 0.8800 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:16:35,785 INFO] Epoch: 524 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:36,072 INFO] Epoch: 524 | ValAcc: 0.8750 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:16:36,682 INFO] Epoch: 525 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:36,974 INFO] Epoch: 525 | ValAcc: 0.8760 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:16:37,587 INFO] Epoch: 526 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:37,885 INFO] Epoch: 526 | ValAcc: 0.8740 | ValLoss: 0.0418 \n",
      "\n",
      "[2017-12-02 05:16:38,493 INFO] Epoch: 527 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:38,785 INFO] Epoch: 527 | ValAcc: 0.8830 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:16:39,407 INFO] Epoch: 528 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:39,705 INFO] Epoch: 528 | ValAcc: 0.8800 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:16:40,320 INFO] Epoch: 529 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:40,617 INFO] Epoch: 529 | ValAcc: 0.8810 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:16:41,246 INFO] Epoch: 530 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:41,536 INFO] Epoch: 530 | ValAcc: 0.8790 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:16:42,164 INFO] Epoch: 531 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:42,461 INFO] Epoch: 531 | ValAcc: 0.8770 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:16:43,100 INFO] Epoch: 532 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:43,393 INFO] Epoch: 532 | ValAcc: 0.8790 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:16:44,010 INFO] Epoch: 533 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:44,303 INFO] Epoch: 533 | ValAcc: 0.8790 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:16:44,933 INFO] Epoch: 534 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:45,223 INFO] Epoch: 534 | ValAcc: 0.8810 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:16:45,843 INFO] Epoch: 535 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:46,138 INFO] Epoch: 535 | ValAcc: 0.8770 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:16:46,761 INFO] Epoch: 536 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:47,057 INFO] Epoch: 536 | ValAcc: 0.8820 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:16:47,672 INFO] Epoch: 537 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:47,959 INFO] Epoch: 537 | ValAcc: 0.8670 | ValLoss: 0.0441 \n",
      "\n",
      "[2017-12-02 05:16:48,576 INFO] Epoch: 538 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:48,871 INFO] Epoch: 538 | ValAcc: 0.8860 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:16:49,498 INFO] Epoch: 539 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:49,793 INFO] Epoch: 539 | ValAcc: 0.8820 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:16:50,417 INFO] Epoch: 540 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:50,714 INFO] Epoch: 540 | ValAcc: 0.8810 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:16:51,343 INFO] Epoch: 541 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:51,641 INFO] Epoch: 541 | ValAcc: 0.8740 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:16:52,252 INFO] Epoch: 542 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:52,549 INFO] Epoch: 542 | ValAcc: 0.8730 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:16:53,167 INFO] Epoch: 543 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:53,458 INFO] Epoch: 543 | ValAcc: 0.8770 | ValLoss: 0.0420 \n",
      "\n",
      "[2017-12-02 05:16:54,063 INFO] Epoch: 544 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:54,359 INFO] Epoch: 544 | ValAcc: 0.8820 | ValLoss: 0.0409 \n",
      "\n",
      "[2017-12-02 05:16:55,010 INFO] Epoch: 545 | TrainAcc: 1.0000 | TrainLoss: 0.0003\n",
      "[2017-12-02 05:16:55,307 INFO] Epoch: 545 | ValAcc: 0.8820 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:16:55,940 INFO] Epoch: 546 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:56,234 INFO] Epoch: 546 | ValAcc: 0.8760 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:16:56,852 INFO] Epoch: 547 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:57,147 INFO] Epoch: 547 | ValAcc: 0.8780 | ValLoss: 0.0420 \n",
      "\n",
      "[2017-12-02 05:16:57,768 INFO] Epoch: 548 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:58,058 INFO] Epoch: 548 | ValAcc: 0.8810 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:16:58,671 INFO] Epoch: 549 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:58,969 INFO] Epoch: 549 | ValAcc: 0.8810 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:16:59,601 INFO] Epoch: 550 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:16:59,893 INFO] Epoch: 550 | ValAcc: 0.8830 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:17:00,520 INFO] Epoch: 551 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:00,818 INFO] Epoch: 551 | ValAcc: 0.8760 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:17:01,431 INFO] Epoch: 552 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:01,733 INFO] Epoch: 552 | ValAcc: 0.8790 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:17:02,349 INFO] Epoch: 553 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:02,651 INFO] Epoch: 553 | ValAcc: 0.8780 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:17:03,260 INFO] Epoch: 554 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:03,564 INFO] Epoch: 554 | ValAcc: 0.8780 | ValLoss: 0.0424 \n",
      "\n",
      "[2017-12-02 05:17:04,184 INFO] Epoch: 555 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:04,479 INFO] Epoch: 555 | ValAcc: 0.8690 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:17:05,118 INFO] Epoch: 556 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:05,432 INFO] Epoch: 556 | ValAcc: 0.8800 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:17:06,055 INFO] Epoch: 557 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:06,351 INFO] Epoch: 557 | ValAcc: 0.8790 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:17:06,968 INFO] Epoch: 558 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:07,275 INFO] Epoch: 558 | ValAcc: 0.8810 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:17:07,914 INFO] Epoch: 559 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:08,206 INFO] Epoch: 559 | ValAcc: 0.8870 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:17:08,825 INFO] Epoch: 560 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:09,122 INFO] Epoch: 560 | ValAcc: 0.8800 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:17:09,758 INFO] Epoch: 561 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:10,051 INFO] Epoch: 561 | ValAcc: 0.8760 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:17:10,666 INFO] Epoch: 562 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:10,973 INFO] Epoch: 562 | ValAcc: 0.8770 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:17:11,608 INFO] Epoch: 563 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:11,898 INFO] Epoch: 563 | ValAcc: 0.8790 | ValLoss: 0.0409 \n",
      "\n",
      "[2017-12-02 05:17:12,521 INFO] Epoch: 564 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:12,820 INFO] Epoch: 564 | ValAcc: 0.8800 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:17:13,447 INFO] Epoch: 565 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:13,738 INFO] Epoch: 565 | ValAcc: 0.8780 | ValLoss: 0.0424 \n",
      "\n",
      "[2017-12-02 05:17:14,355 INFO] Epoch: 566 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:14,648 INFO] Epoch: 566 | ValAcc: 0.8780 | ValLoss: 0.0439 \n",
      "\n",
      "[2017-12-02 05:17:15,277 INFO] Epoch: 567 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:17:15,567 INFO] Epoch: 567 | ValAcc: 0.8780 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:17:16,186 INFO] Epoch: 568 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:16,482 INFO] Epoch: 568 | ValAcc: 0.8790 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:17:17,099 INFO] Epoch: 569 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:17,394 INFO] Epoch: 569 | ValAcc: 0.8830 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:17:18,011 INFO] Epoch: 570 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:18,305 INFO] Epoch: 570 | ValAcc: 0.8730 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:17:18,916 INFO] Epoch: 571 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:19,229 INFO] Epoch: 571 | ValAcc: 0.8760 | ValLoss: 0.0418 \n",
      "\n",
      "[2017-12-02 05:17:19,852 INFO] Epoch: 572 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:20,137 INFO] Epoch: 572 | ValAcc: 0.8800 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:17:20,766 INFO] Epoch: 573 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:21,050 INFO] Epoch: 573 | ValAcc: 0.8810 | ValLoss: 0.0409 \n",
      "\n",
      "[2017-12-02 05:17:21,672 INFO] Epoch: 574 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:21,975 INFO] Epoch: 574 | ValAcc: 0.8810 | ValLoss: 0.0410 \n",
      "\n",
      "[2017-12-02 05:17:22,602 INFO] Epoch: 575 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:22,898 INFO] Epoch: 575 | ValAcc: 0.8800 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:17:23,500 INFO] Epoch: 576 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:23,796 INFO] Epoch: 576 | ValAcc: 0.8780 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:17:24,403 INFO] Epoch: 577 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:24,701 INFO] Epoch: 577 | ValAcc: 0.8810 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:17:25,338 INFO] Epoch: 578 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:25,635 INFO] Epoch: 578 | ValAcc: 0.8770 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:17:26,247 INFO] Epoch: 579 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:26,535 INFO] Epoch: 579 | ValAcc: 0.8730 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:17:27,151 INFO] Epoch: 580 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:27,453 INFO] Epoch: 580 | ValAcc: 0.8750 | ValLoss: 0.0418 \n",
      "\n",
      "[2017-12-02 05:17:28,082 INFO] Epoch: 581 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:28,372 INFO] Epoch: 581 | ValAcc: 0.8810 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:17:28,997 INFO] Epoch: 582 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:29,287 INFO] Epoch: 582 | ValAcc: 0.8740 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:17:29,909 INFO] Epoch: 583 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:30,201 INFO] Epoch: 583 | ValAcc: 0.8820 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:17:30,815 INFO] Epoch: 584 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:31,106 INFO] Epoch: 584 | ValAcc: 0.8830 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:17:31,737 INFO] Epoch: 585 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:32,031 INFO] Epoch: 585 | ValAcc: 0.8850 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:17:32,654 INFO] Epoch: 586 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:32,950 INFO] Epoch: 586 | ValAcc: 0.8750 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:17:33,570 INFO] Epoch: 587 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:33,867 INFO] Epoch: 587 | ValAcc: 0.8850 | ValLoss: 0.0411 \n",
      "\n",
      "[2017-12-02 05:17:34,492 INFO] Epoch: 588 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:34,790 INFO] Epoch: 588 | ValAcc: 0.8870 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:17:35,412 INFO] Epoch: 589 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:35,704 INFO] Epoch: 589 | ValAcc: 0.8790 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:17:36,319 INFO] Epoch: 590 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:36,618 INFO] Epoch: 590 | ValAcc: 0.8780 | ValLoss: 0.0418 \n",
      "\n",
      "[2017-12-02 05:17:37,244 INFO] Epoch: 591 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:37,536 INFO] Epoch: 591 | ValAcc: 0.8790 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:17:38,157 INFO] Epoch: 592 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:38,444 INFO] Epoch: 592 | ValAcc: 0.8740 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:17:39,068 INFO] Epoch: 593 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:39,367 INFO] Epoch: 593 | ValAcc: 0.8790 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:17:39,989 INFO] Epoch: 594 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:40,282 INFO] Epoch: 594 | ValAcc: 0.8830 | ValLoss: 0.0420 \n",
      "\n",
      "[2017-12-02 05:17:40,918 INFO] Epoch: 595 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:41,208 INFO] Epoch: 595 | ValAcc: 0.8730 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:17:41,819 INFO] Epoch: 596 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:42,106 INFO] Epoch: 596 | ValAcc: 0.8790 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:17:42,746 INFO] Epoch: 597 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:43,038 INFO] Epoch: 597 | ValAcc: 0.8770 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:17:43,663 INFO] Epoch: 598 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:43,964 INFO] Epoch: 598 | ValAcc: 0.8830 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:17:44,603 INFO] Epoch: 599 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:44,890 INFO] Epoch: 599 | ValAcc: 0.8900 | ValLoss: 0.0420 \n",
      "\n",
      "[2017-12-02 05:17:45,511 INFO] Epoch: 600 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:45,802 INFO] Epoch: 600 | ValAcc: 0.8780 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:17:46,410 INFO] Epoch: 601 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:46,708 INFO] Epoch: 601 | ValAcc: 0.8820 | ValLoss: 0.0412 \n",
      "\n",
      "[2017-12-02 05:17:47,332 INFO] Epoch: 602 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:47,629 INFO] Epoch: 602 | ValAcc: 0.8870 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:17:48,233 INFO] Epoch: 603 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:48,542 INFO] Epoch: 603 | ValAcc: 0.8820 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:17:49,166 INFO] Epoch: 604 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:49,462 INFO] Epoch: 604 | ValAcc: 0.8810 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:17:50,092 INFO] Epoch: 605 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:50,402 INFO] Epoch: 605 | ValAcc: 0.8780 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:17:51,026 INFO] Epoch: 606 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:51,314 INFO] Epoch: 606 | ValAcc: 0.8780 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:17:51,937 INFO] Epoch: 607 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:52,244 INFO] Epoch: 607 | ValAcc: 0.8790 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:17:52,855 INFO] Epoch: 608 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:53,154 INFO] Epoch: 608 | ValAcc: 0.8840 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:17:53,772 INFO] Epoch: 609 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:54,079 INFO] Epoch: 609 | ValAcc: 0.8800 | ValLoss: 0.0418 \n",
      "\n",
      "[2017-12-02 05:17:54,712 INFO] Epoch: 610 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:55,000 INFO] Epoch: 610 | ValAcc: 0.8790 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:17:55,635 INFO] Epoch: 611 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:55,940 INFO] Epoch: 611 | ValAcc: 0.8790 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:17:56,567 INFO] Epoch: 612 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:56,860 INFO] Epoch: 612 | ValAcc: 0.8830 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:17:57,485 INFO] Epoch: 613 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:57,800 INFO] Epoch: 613 | ValAcc: 0.8780 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:17:58,406 INFO] Epoch: 614 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:58,705 INFO] Epoch: 614 | ValAcc: 0.8810 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:17:59,332 INFO] Epoch: 615 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:17:59,631 INFO] Epoch: 615 | ValAcc: 0.8780 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:18:00,269 INFO] Epoch: 616 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:00,564 INFO] Epoch: 616 | ValAcc: 0.8800 | ValLoss: 0.0414 \n",
      "\n",
      "[2017-12-02 05:18:01,178 INFO] Epoch: 617 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:01,468 INFO] Epoch: 617 | ValAcc: 0.8780 | ValLoss: 0.0418 \n",
      "\n",
      "[2017-12-02 05:18:02,073 INFO] Epoch: 618 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:02,371 INFO] Epoch: 618 | ValAcc: 0.8780 | ValLoss: 0.0419 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:18:02,985 INFO] Epoch: 619 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:03,282 INFO] Epoch: 619 | ValAcc: 0.8820 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:18:03,918 INFO] Epoch: 620 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:04,212 INFO] Epoch: 620 | ValAcc: 0.8820 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:18:04,841 INFO] Epoch: 621 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:05,134 INFO] Epoch: 621 | ValAcc: 0.8830 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:18:05,778 INFO] Epoch: 622 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:06,073 INFO] Epoch: 622 | ValAcc: 0.8780 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:18:06,696 INFO] Epoch: 623 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:06,998 INFO] Epoch: 623 | ValAcc: 0.8780 | ValLoss: 0.0424 \n",
      "\n",
      "[2017-12-02 05:18:07,614 INFO] Epoch: 624 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:07,908 INFO] Epoch: 624 | ValAcc: 0.8780 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:18:08,532 INFO] Epoch: 625 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:08,828 INFO] Epoch: 625 | ValAcc: 0.8800 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:18:09,443 INFO] Epoch: 626 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:09,733 INFO] Epoch: 626 | ValAcc: 0.8810 | ValLoss: 0.0420 \n",
      "\n",
      "[2017-12-02 05:18:10,361 INFO] Epoch: 627 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:10,656 INFO] Epoch: 627 | ValAcc: 0.8820 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:18:11,284 INFO] Epoch: 628 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:11,580 INFO] Epoch: 628 | ValAcc: 0.8790 | ValLoss: 0.0413 \n",
      "\n",
      "[2017-12-02 05:18:12,198 INFO] Epoch: 629 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:12,488 INFO] Epoch: 629 | ValAcc: 0.8790 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:18:13,111 INFO] Epoch: 630 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:13,405 INFO] Epoch: 630 | ValAcc: 0.8810 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:18:14,006 INFO] Epoch: 631 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:14,294 INFO] Epoch: 631 | ValAcc: 0.8800 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:18:14,916 INFO] Epoch: 632 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:15,203 INFO] Epoch: 632 | ValAcc: 0.8800 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:18:15,820 INFO] Epoch: 633 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:16,118 INFO] Epoch: 633 | ValAcc: 0.8790 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:18:16,738 INFO] Epoch: 634 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:17,033 INFO] Epoch: 634 | ValAcc: 0.8730 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:18:17,661 INFO] Epoch: 635 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:17,959 INFO] Epoch: 635 | ValAcc: 0.8800 | ValLoss: 0.0418 \n",
      "\n",
      "[2017-12-02 05:18:18,572 INFO] Epoch: 636 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:18,865 INFO] Epoch: 636 | ValAcc: 0.8820 | ValLoss: 0.0418 \n",
      "\n",
      "[2017-12-02 05:18:19,487 INFO] Epoch: 637 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:19,789 INFO] Epoch: 637 | ValAcc: 0.8830 | ValLoss: 0.0424 \n",
      "\n",
      "[2017-12-02 05:18:20,413 INFO] Epoch: 638 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:20,714 INFO] Epoch: 638 | ValAcc: 0.8760 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:18:21,336 INFO] Epoch: 639 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:21,634 INFO] Epoch: 639 | ValAcc: 0.8780 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:18:22,260 INFO] Epoch: 640 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:22,549 INFO] Epoch: 640 | ValAcc: 0.8810 | ValLoss: 0.0420 \n",
      "\n",
      "[2017-12-02 05:18:23,167 INFO] Epoch: 641 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:23,460 INFO] Epoch: 641 | ValAcc: 0.8810 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:18:24,096 INFO] Epoch: 642 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:24,387 INFO] Epoch: 642 | ValAcc: 0.8740 | ValLoss: 0.0420 \n",
      "\n",
      "[2017-12-02 05:18:25,013 INFO] Epoch: 643 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:25,303 INFO] Epoch: 643 | ValAcc: 0.8800 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:18:25,925 INFO] Epoch: 644 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:26,212 INFO] Epoch: 644 | ValAcc: 0.8810 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:18:26,828 INFO] Epoch: 645 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:27,117 INFO] Epoch: 645 | ValAcc: 0.8770 | ValLoss: 0.0420 \n",
      "\n",
      "[2017-12-02 05:18:27,741 INFO] Epoch: 646 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:28,035 INFO] Epoch: 646 | ValAcc: 0.8770 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:18:28,655 INFO] Epoch: 647 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:28,951 INFO] Epoch: 647 | ValAcc: 0.8780 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:18:29,556 INFO] Epoch: 648 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:29,853 INFO] Epoch: 648 | ValAcc: 0.8780 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:18:30,473 INFO] Epoch: 649 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:30,770 INFO] Epoch: 649 | ValAcc: 0.8790 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:18:31,393 INFO] Epoch: 650 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:31,690 INFO] Epoch: 650 | ValAcc: 0.8790 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:18:32,302 INFO] Epoch: 651 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:32,601 INFO] Epoch: 651 | ValAcc: 0.8820 | ValLoss: 0.0426 \n",
      "\n",
      "[2017-12-02 05:18:33,217 INFO] Epoch: 652 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:33,517 INFO] Epoch: 652 | ValAcc: 0.8830 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:18:34,135 INFO] Epoch: 653 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:34,432 INFO] Epoch: 653 | ValAcc: 0.8760 | ValLoss: 0.0420 \n",
      "\n",
      "[2017-12-02 05:18:35,042 INFO] Epoch: 654 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:35,341 INFO] Epoch: 654 | ValAcc: 0.8820 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:18:35,965 INFO] Epoch: 655 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:36,261 INFO] Epoch: 655 | ValAcc: 0.8780 | ValLoss: 0.0418 \n",
      "\n",
      "[2017-12-02 05:18:36,882 INFO] Epoch: 656 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:37,182 INFO] Epoch: 656 | ValAcc: 0.8810 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:18:37,809 INFO] Epoch: 657 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:38,101 INFO] Epoch: 657 | ValAcc: 0.8800 | ValLoss: 0.0418 \n",
      "\n",
      "[2017-12-02 05:18:38,725 INFO] Epoch: 658 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:39,034 INFO] Epoch: 658 | ValAcc: 0.8780 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:18:39,659 INFO] Epoch: 659 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:39,951 INFO] Epoch: 659 | ValAcc: 0.8740 | ValLoss: 0.0442 \n",
      "\n",
      "[2017-12-02 05:18:40,567 INFO] Epoch: 660 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:40,876 INFO] Epoch: 660 | ValAcc: 0.8870 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:18:41,481 INFO] Epoch: 661 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:41,773 INFO] Epoch: 661 | ValAcc: 0.8830 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:18:42,402 INFO] Epoch: 662 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:42,712 INFO] Epoch: 662 | ValAcc: 0.8780 | ValLoss: 0.0420 \n",
      "\n",
      "[2017-12-02 05:18:43,327 INFO] Epoch: 663 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:43,626 INFO] Epoch: 663 | ValAcc: 0.8810 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:18:44,242 INFO] Epoch: 664 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:44,534 INFO] Epoch: 664 | ValAcc: 0.8800 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:18:45,163 INFO] Epoch: 665 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:45,458 INFO] Epoch: 665 | ValAcc: 0.8790 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:18:46,085 INFO] Epoch: 666 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:46,372 INFO] Epoch: 666 | ValAcc: 0.8780 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:18:46,979 INFO] Epoch: 667 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:47,269 INFO] Epoch: 667 | ValAcc: 0.8810 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:18:47,886 INFO] Epoch: 668 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:48,182 INFO] Epoch: 668 | ValAcc: 0.8780 | ValLoss: 0.0420 \n",
      "\n",
      "[2017-12-02 05:18:48,791 INFO] Epoch: 669 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:49,097 INFO] Epoch: 669 | ValAcc: 0.8830 | ValLoss: 0.0420 \n",
      "\n",
      "[2017-12-02 05:18:49,708 INFO] Epoch: 670 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:18:50,006 INFO] Epoch: 670 | ValAcc: 0.8800 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:18:50,630 INFO] Epoch: 671 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:50,923 INFO] Epoch: 671 | ValAcc: 0.8730 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:18:51,563 INFO] Epoch: 672 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:51,854 INFO] Epoch: 672 | ValAcc: 0.8820 | ValLoss: 0.0420 \n",
      "\n",
      "[2017-12-02 05:18:52,475 INFO] Epoch: 673 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:52,770 INFO] Epoch: 673 | ValAcc: 0.8820 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:18:53,380 INFO] Epoch: 674 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:53,676 INFO] Epoch: 674 | ValAcc: 0.8820 | ValLoss: 0.0418 \n",
      "\n",
      "[2017-12-02 05:18:54,298 INFO] Epoch: 675 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:18:54,595 INFO] Epoch: 675 | ValAcc: 0.8830 | ValLoss: 0.0415 \n",
      "\n",
      "[2017-12-02 05:18:55,213 INFO] Epoch: 676 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:55,505 INFO] Epoch: 676 | ValAcc: 0.8810 | ValLoss: 0.0416 \n",
      "\n",
      "[2017-12-02 05:18:56,128 INFO] Epoch: 677 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:56,419 INFO] Epoch: 677 | ValAcc: 0.8720 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:18:57,024 INFO] Epoch: 678 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:57,315 INFO] Epoch: 678 | ValAcc: 0.8800 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:18:57,944 INFO] Epoch: 679 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:58,240 INFO] Epoch: 679 | ValAcc: 0.8770 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:18:58,848 INFO] Epoch: 680 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:18:59,159 INFO] Epoch: 680 | ValAcc: 0.8820 | ValLoss: 0.0417 \n",
      "\n",
      "[2017-12-02 05:18:59,763 INFO] Epoch: 681 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:00,056 INFO] Epoch: 681 | ValAcc: 0.8840 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:19:00,690 INFO] Epoch: 682 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:00,982 INFO] Epoch: 682 | ValAcc: 0.8800 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:19:01,603 INFO] Epoch: 683 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:01,897 INFO] Epoch: 683 | ValAcc: 0.8800 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:19:02,516 INFO] Epoch: 684 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:02,807 INFO] Epoch: 684 | ValAcc: 0.8760 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:19:03,405 INFO] Epoch: 685 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:03,700 INFO] Epoch: 685 | ValAcc: 0.8730 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:19:04,311 INFO] Epoch: 686 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:04,611 INFO] Epoch: 686 | ValAcc: 0.8790 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:19:05,237 INFO] Epoch: 687 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:05,525 INFO] Epoch: 687 | ValAcc: 0.8810 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:19:06,158 INFO] Epoch: 688 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:06,442 INFO] Epoch: 688 | ValAcc: 0.8780 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:19:07,078 INFO] Epoch: 689 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:07,372 INFO] Epoch: 689 | ValAcc: 0.8800 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:19:07,974 INFO] Epoch: 690 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:08,267 INFO] Epoch: 690 | ValAcc: 0.8810 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:19:08,892 INFO] Epoch: 691 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:09,183 INFO] Epoch: 691 | ValAcc: 0.8770 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:19:09,844 INFO] Epoch: 692 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:10,138 INFO] Epoch: 692 | ValAcc: 0.8830 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:19:10,758 INFO] Epoch: 693 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:11,053 INFO] Epoch: 693 | ValAcc: 0.8810 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:19:11,696 INFO] Epoch: 694 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:11,986 INFO] Epoch: 694 | ValAcc: 0.8840 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:19:12,591 INFO] Epoch: 695 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:12,894 INFO] Epoch: 695 | ValAcc: 0.8800 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:19:13,508 INFO] Epoch: 696 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:13,802 INFO] Epoch: 696 | ValAcc: 0.8850 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:19:14,432 INFO] Epoch: 697 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:14,724 INFO] Epoch: 697 | ValAcc: 0.8840 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:19:15,348 INFO] Epoch: 698 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:15,636 INFO] Epoch: 698 | ValAcc: 0.8820 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:19:16,276 INFO] Epoch: 699 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:16,575 INFO] Epoch: 699 | ValAcc: 0.8790 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:19:17,178 INFO] Epoch: 700 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:17,478 INFO] Epoch: 700 | ValAcc: 0.8780 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:19:18,106 INFO] Epoch: 701 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:18,406 INFO] Epoch: 701 | ValAcc: 0.8810 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:19:19,028 INFO] Epoch: 702 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:19,331 INFO] Epoch: 702 | ValAcc: 0.8770 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:19:19,973 INFO] Epoch: 703 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:20,279 INFO] Epoch: 703 | ValAcc: 0.8800 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:19:20,902 INFO] Epoch: 704 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:21,204 INFO] Epoch: 704 | ValAcc: 0.8720 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:19:21,809 INFO] Epoch: 705 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:22,111 INFO] Epoch: 705 | ValAcc: 0.8790 | ValLoss: 0.0426 \n",
      "\n",
      "[2017-12-02 05:19:22,728 INFO] Epoch: 706 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:23,022 INFO] Epoch: 706 | ValAcc: 0.8830 | ValLoss: 0.0420 \n",
      "\n",
      "[2017-12-02 05:19:23,637 INFO] Epoch: 707 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:23,933 INFO] Epoch: 707 | ValAcc: 0.8800 | ValLoss: 0.0420 \n",
      "\n",
      "[2017-12-02 05:19:24,548 INFO] Epoch: 708 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:24,845 INFO] Epoch: 708 | ValAcc: 0.8850 | ValLoss: 0.0419 \n",
      "\n",
      "[2017-12-02 05:19:25,461 INFO] Epoch: 709 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:25,757 INFO] Epoch: 709 | ValAcc: 0.8800 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:19:26,390 INFO] Epoch: 710 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:26,686 INFO] Epoch: 710 | ValAcc: 0.8800 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:19:27,285 INFO] Epoch: 711 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:27,582 INFO] Epoch: 711 | ValAcc: 0.8810 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:19:28,201 INFO] Epoch: 712 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:28,493 INFO] Epoch: 712 | ValAcc: 0.8790 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:19:29,108 INFO] Epoch: 713 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:29,411 INFO] Epoch: 713 | ValAcc: 0.8760 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:19:30,019 INFO] Epoch: 714 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:30,313 INFO] Epoch: 714 | ValAcc: 0.8800 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:19:30,934 INFO] Epoch: 715 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:31,228 INFO] Epoch: 715 | ValAcc: 0.8790 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:19:31,838 INFO] Epoch: 716 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:32,137 INFO] Epoch: 716 | ValAcc: 0.8820 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:19:32,765 INFO] Epoch: 717 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:33,059 INFO] Epoch: 717 | ValAcc: 0.8800 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:19:33,671 INFO] Epoch: 718 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:33,965 INFO] Epoch: 718 | ValAcc: 0.8760 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:19:34,583 INFO] Epoch: 719 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:34,879 INFO] Epoch: 719 | ValAcc: 0.8770 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:19:35,489 INFO] Epoch: 720 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:35,783 INFO] Epoch: 720 | ValAcc: 0.8780 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:19:36,414 INFO] Epoch: 721 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:36,710 INFO] Epoch: 721 | ValAcc: 0.8810 | ValLoss: 0.0426 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:19:37,327 INFO] Epoch: 722 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:37,626 INFO] Epoch: 722 | ValAcc: 0.8770 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:19:38,254 INFO] Epoch: 723 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:38,543 INFO] Epoch: 723 | ValAcc: 0.8790 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:19:39,162 INFO] Epoch: 724 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:39,451 INFO] Epoch: 724 | ValAcc: 0.8780 | ValLoss: 0.0424 \n",
      "\n",
      "[2017-12-02 05:19:40,056 INFO] Epoch: 725 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:40,352 INFO] Epoch: 725 | ValAcc: 0.8810 | ValLoss: 0.0426 \n",
      "\n",
      "[2017-12-02 05:19:40,984 INFO] Epoch: 726 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:41,277 INFO] Epoch: 726 | ValAcc: 0.8820 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:19:41,899 INFO] Epoch: 727 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:42,193 INFO] Epoch: 727 | ValAcc: 0.8840 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:19:42,813 INFO] Epoch: 728 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:43,109 INFO] Epoch: 728 | ValAcc: 0.8820 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:19:43,733 INFO] Epoch: 729 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:44,028 INFO] Epoch: 729 | ValAcc: 0.8780 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:19:44,641 INFO] Epoch: 730 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:44,937 INFO] Epoch: 730 | ValAcc: 0.8780 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:19:45,561 INFO] Epoch: 731 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:45,855 INFO] Epoch: 731 | ValAcc: 0.8820 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:19:46,481 INFO] Epoch: 732 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:46,782 INFO] Epoch: 732 | ValAcc: 0.8810 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:19:47,401 INFO] Epoch: 733 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:47,699 INFO] Epoch: 733 | ValAcc: 0.8820 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:19:48,320 INFO] Epoch: 734 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:48,614 INFO] Epoch: 734 | ValAcc: 0.8840 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:19:49,245 INFO] Epoch: 735 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:49,538 INFO] Epoch: 735 | ValAcc: 0.8830 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:19:50,170 INFO] Epoch: 736 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:50,464 INFO] Epoch: 736 | ValAcc: 0.8840 | ValLoss: 0.0424 \n",
      "\n",
      "[2017-12-02 05:19:51,087 INFO] Epoch: 737 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:51,388 INFO] Epoch: 737 | ValAcc: 0.8840 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:19:51,990 INFO] Epoch: 738 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:52,277 INFO] Epoch: 738 | ValAcc: 0.8740 | ValLoss: 0.0436 \n",
      "\n",
      "[2017-12-02 05:19:52,925 INFO] Epoch: 739 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:53,217 INFO] Epoch: 739 | ValAcc: 0.8730 | ValLoss: 0.0439 \n",
      "\n",
      "[2017-12-02 05:19:53,830 INFO] Epoch: 740 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:54,118 INFO] Epoch: 740 | ValAcc: 0.8840 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:19:54,740 INFO] Epoch: 741 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:55,034 INFO] Epoch: 741 | ValAcc: 0.8820 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:19:55,666 INFO] Epoch: 742 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:55,966 INFO] Epoch: 742 | ValAcc: 0.8830 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:19:56,602 INFO] Epoch: 743 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:56,891 INFO] Epoch: 743 | ValAcc: 0.8810 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:19:57,494 INFO] Epoch: 744 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:57,788 INFO] Epoch: 744 | ValAcc: 0.8830 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:19:58,387 INFO] Epoch: 745 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:19:58,681 INFO] Epoch: 745 | ValAcc: 0.8790 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:19:59,310 INFO] Epoch: 746 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:19:59,613 INFO] Epoch: 746 | ValAcc: 0.8800 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:20:00,233 INFO] Epoch: 747 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:00,532 INFO] Epoch: 747 | ValAcc: 0.8760 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:20:01,152 INFO] Epoch: 748 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:01,448 INFO] Epoch: 748 | ValAcc: 0.8770 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:20:02,067 INFO] Epoch: 749 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:02,358 INFO] Epoch: 749 | ValAcc: 0.8800 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:20:02,987 INFO] Epoch: 750 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:03,288 INFO] Epoch: 750 | ValAcc: 0.8820 | ValLoss: 0.0422 \n",
      "\n",
      "[2017-12-02 05:20:03,909 INFO] Epoch: 751 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:04,201 INFO] Epoch: 751 | ValAcc: 0.8790 | ValLoss: 0.0424 \n",
      "\n",
      "[2017-12-02 05:20:04,824 INFO] Epoch: 752 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:05,127 INFO] Epoch: 752 | ValAcc: 0.8800 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:20:05,754 INFO] Epoch: 753 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:06,041 INFO] Epoch: 753 | ValAcc: 0.8780 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:20:06,662 INFO] Epoch: 754 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:06,959 INFO] Epoch: 754 | ValAcc: 0.8840 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:20:07,583 INFO] Epoch: 755 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:07,877 INFO] Epoch: 755 | ValAcc: 0.8780 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:20:08,500 INFO] Epoch: 756 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:08,800 INFO] Epoch: 756 | ValAcc: 0.8850 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:20:09,426 INFO] Epoch: 757 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:09,726 INFO] Epoch: 757 | ValAcc: 0.8780 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:20:10,333 INFO] Epoch: 758 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:10,629 INFO] Epoch: 758 | ValAcc: 0.8790 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:20:11,267 INFO] Epoch: 759 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:11,554 INFO] Epoch: 759 | ValAcc: 0.8770 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:20:12,158 INFO] Epoch: 760 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:12,450 INFO] Epoch: 760 | ValAcc: 0.8810 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:20:13,071 INFO] Epoch: 761 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:13,365 INFO] Epoch: 761 | ValAcc: 0.8800 | ValLoss: 0.0424 \n",
      "\n",
      "[2017-12-02 05:20:13,978 INFO] Epoch: 762 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:14,285 INFO] Epoch: 762 | ValAcc: 0.8790 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:20:14,903 INFO] Epoch: 763 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:15,200 INFO] Epoch: 763 | ValAcc: 0.8760 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:20:15,822 INFO] Epoch: 764 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:16,115 INFO] Epoch: 764 | ValAcc: 0.8780 | ValLoss: 0.0439 \n",
      "\n",
      "[2017-12-02 05:20:16,756 INFO] Epoch: 765 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:17,050 INFO] Epoch: 765 | ValAcc: 0.8790 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:20:17,676 INFO] Epoch: 766 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:17,971 INFO] Epoch: 766 | ValAcc: 0.8830 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:20:18,590 INFO] Epoch: 767 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:18,889 INFO] Epoch: 767 | ValAcc: 0.8800 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:20:19,533 INFO] Epoch: 768 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:19,832 INFO] Epoch: 768 | ValAcc: 0.8830 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:20:20,441 INFO] Epoch: 769 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:20,734 INFO] Epoch: 769 | ValAcc: 0.8780 | ValLoss: 0.0424 \n",
      "\n",
      "[2017-12-02 05:20:21,337 INFO] Epoch: 770 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:21,635 INFO] Epoch: 770 | ValAcc: 0.8830 | ValLoss: 0.0426 \n",
      "\n",
      "[2017-12-02 05:20:22,247 INFO] Epoch: 771 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:22,549 INFO] Epoch: 771 | ValAcc: 0.8800 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:20:23,170 INFO] Epoch: 772 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:23,475 INFO] Epoch: 772 | ValAcc: 0.8790 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:20:24,105 INFO] Epoch: 773 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:20:24,401 INFO] Epoch: 773 | ValAcc: 0.8780 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:20:25,039 INFO] Epoch: 774 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:25,329 INFO] Epoch: 774 | ValAcc: 0.8800 | ValLoss: 0.0424 \n",
      "\n",
      "[2017-12-02 05:20:25,948 INFO] Epoch: 775 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:26,237 INFO] Epoch: 775 | ValAcc: 0.8800 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:20:26,874 INFO] Epoch: 776 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:27,168 INFO] Epoch: 776 | ValAcc: 0.8820 | ValLoss: 0.0421 \n",
      "\n",
      "[2017-12-02 05:20:27,796 INFO] Epoch: 777 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:28,094 INFO] Epoch: 777 | ValAcc: 0.8800 | ValLoss: 0.0426 \n",
      "\n",
      "[2017-12-02 05:20:28,714 INFO] Epoch: 778 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:29,010 INFO] Epoch: 778 | ValAcc: 0.8770 | ValLoss: 0.0439 \n",
      "\n",
      "[2017-12-02 05:20:29,620 INFO] Epoch: 779 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:29,915 INFO] Epoch: 779 | ValAcc: 0.8780 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:20:30,547 INFO] Epoch: 780 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:30,850 INFO] Epoch: 780 | ValAcc: 0.8760 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:20:31,469 INFO] Epoch: 781 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:31,759 INFO] Epoch: 781 | ValAcc: 0.8810 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:20:32,381 INFO] Epoch: 782 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:32,681 INFO] Epoch: 782 | ValAcc: 0.8840 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:20:33,299 INFO] Epoch: 783 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:33,592 INFO] Epoch: 783 | ValAcc: 0.8850 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:20:34,208 INFO] Epoch: 784 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:34,491 INFO] Epoch: 784 | ValAcc: 0.8790 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:20:35,096 INFO] Epoch: 785 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:35,388 INFO] Epoch: 785 | ValAcc: 0.8800 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:20:36,004 INFO] Epoch: 786 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:36,295 INFO] Epoch: 786 | ValAcc: 0.8800 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:20:36,934 INFO] Epoch: 787 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:37,231 INFO] Epoch: 787 | ValAcc: 0.8790 | ValLoss: 0.0438 \n",
      "\n",
      "[2017-12-02 05:20:37,852 INFO] Epoch: 788 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:38,147 INFO] Epoch: 788 | ValAcc: 0.8790 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:20:38,775 INFO] Epoch: 789 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:39,071 INFO] Epoch: 789 | ValAcc: 0.8800 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:20:39,702 INFO] Epoch: 790 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:40,071 INFO] Epoch: 790 | ValAcc: 0.8710 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:20:40,768 INFO] Epoch: 791 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:41,061 INFO] Epoch: 791 | ValAcc: 0.8790 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:20:41,697 INFO] Epoch: 792 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:41,995 INFO] Epoch: 792 | ValAcc: 0.8800 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:20:42,614 INFO] Epoch: 793 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:42,912 INFO] Epoch: 793 | ValAcc: 0.8820 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:20:43,533 INFO] Epoch: 794 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:43,825 INFO] Epoch: 794 | ValAcc: 0.8760 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:20:44,434 INFO] Epoch: 795 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:44,727 INFO] Epoch: 795 | ValAcc: 0.8820 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:20:45,334 INFO] Epoch: 796 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:45,627 INFO] Epoch: 796 | ValAcc: 0.8810 | ValLoss: 0.0441 \n",
      "\n",
      "[2017-12-02 05:20:46,245 INFO] Epoch: 797 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:46,544 INFO] Epoch: 797 | ValAcc: 0.8820 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:20:47,170 INFO] Epoch: 798 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:47,462 INFO] Epoch: 798 | ValAcc: 0.8720 | ValLoss: 0.0439 \n",
      "\n",
      "[2017-12-02 05:20:48,091 INFO] Epoch: 799 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:48,379 INFO] Epoch: 799 | ValAcc: 0.8770 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:20:48,996 INFO] Epoch: 800 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:49,305 INFO] Epoch: 800 | ValAcc: 0.8770 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:20:49,933 INFO] Epoch: 801 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:50,228 INFO] Epoch: 801 | ValAcc: 0.8760 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:20:50,843 INFO] Epoch: 802 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:51,137 INFO] Epoch: 802 | ValAcc: 0.8810 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:20:51,750 INFO] Epoch: 803 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:52,044 INFO] Epoch: 803 | ValAcc: 0.8770 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:20:52,666 INFO] Epoch: 804 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:20:52,968 INFO] Epoch: 804 | ValAcc: 0.8790 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:20:53,585 INFO] Epoch: 805 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:53,895 INFO] Epoch: 805 | ValAcc: 0.8780 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:20:54,513 INFO] Epoch: 806 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:54,805 INFO] Epoch: 806 | ValAcc: 0.8800 | ValLoss: 0.0423 \n",
      "\n",
      "[2017-12-02 05:20:55,430 INFO] Epoch: 807 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:55,747 INFO] Epoch: 807 | ValAcc: 0.8810 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:20:56,360 INFO] Epoch: 808 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:56,651 INFO] Epoch: 808 | ValAcc: 0.8850 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:20:57,289 INFO] Epoch: 809 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:57,608 INFO] Epoch: 809 | ValAcc: 0.8820 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:20:58,230 INFO] Epoch: 810 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:58,523 INFO] Epoch: 810 | ValAcc: 0.8790 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:20:59,141 INFO] Epoch: 811 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:20:59,443 INFO] Epoch: 811 | ValAcc: 0.8750 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:21:00,056 INFO] Epoch: 812 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:00,350 INFO] Epoch: 812 | ValAcc: 0.8800 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:21:00,980 INFO] Epoch: 813 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:01,284 INFO] Epoch: 813 | ValAcc: 0.8800 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:21:01,912 INFO] Epoch: 814 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:02,210 INFO] Epoch: 814 | ValAcc: 0.8810 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:21:02,816 INFO] Epoch: 815 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:03,108 INFO] Epoch: 815 | ValAcc: 0.8810 | ValLoss: 0.0426 \n",
      "\n",
      "[2017-12-02 05:21:03,728 INFO] Epoch: 816 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:04,020 INFO] Epoch: 816 | ValAcc: 0.8740 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:21:04,636 INFO] Epoch: 817 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:04,935 INFO] Epoch: 817 | ValAcc: 0.8820 | ValLoss: 0.0426 \n",
      "\n",
      "[2017-12-02 05:21:05,553 INFO] Epoch: 818 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:05,852 INFO] Epoch: 818 | ValAcc: 0.8810 | ValLoss: 0.0426 \n",
      "\n",
      "[2017-12-02 05:21:06,476 INFO] Epoch: 819 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:21:06,778 INFO] Epoch: 819 | ValAcc: 0.8820 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:21:07,414 INFO] Epoch: 820 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:07,712 INFO] Epoch: 820 | ValAcc: 0.8810 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:21:08,342 INFO] Epoch: 821 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:08,635 INFO] Epoch: 821 | ValAcc: 0.8780 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:21:09,263 INFO] Epoch: 822 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:09,576 INFO] Epoch: 822 | ValAcc: 0.8800 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:21:10,193 INFO] Epoch: 823 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:10,489 INFO] Epoch: 823 | ValAcc: 0.8820 | ValLoss: 0.0426 \n",
      "\n",
      "[2017-12-02 05:21:11,118 INFO] Epoch: 824 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:21:11,438 INFO] Epoch: 824 | ValAcc: 0.8630 | ValLoss: 0.0499 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:21:12,061 INFO] Epoch: 825 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:12,356 INFO] Epoch: 825 | ValAcc: 0.8800 | ValLoss: 0.0442 \n",
      "\n",
      "[2017-12-02 05:21:12,982 INFO] Epoch: 826 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:13,277 INFO] Epoch: 826 | ValAcc: 0.8780 | ValLoss: 0.0452 \n",
      "\n",
      "[2017-12-02 05:21:13,899 INFO] Epoch: 827 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:14,196 INFO] Epoch: 827 | ValAcc: 0.8810 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:21:14,808 INFO] Epoch: 828 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:15,100 INFO] Epoch: 828 | ValAcc: 0.8790 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:21:15,722 INFO] Epoch: 829 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:16,010 INFO] Epoch: 829 | ValAcc: 0.8800 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:21:16,624 INFO] Epoch: 830 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:16,917 INFO] Epoch: 830 | ValAcc: 0.8810 | ValLoss: 0.0425 \n",
      "\n",
      "[2017-12-02 05:21:17,556 INFO] Epoch: 831 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:17,852 INFO] Epoch: 831 | ValAcc: 0.8800 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:21:18,480 INFO] Epoch: 832 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:21:18,775 INFO] Epoch: 832 | ValAcc: 0.8740 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:21:19,406 INFO] Epoch: 833 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:19,704 INFO] Epoch: 833 | ValAcc: 0.8780 | ValLoss: 0.0436 \n",
      "\n",
      "[2017-12-02 05:21:20,326 INFO] Epoch: 834 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:20,622 INFO] Epoch: 834 | ValAcc: 0.8790 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:21:21,244 INFO] Epoch: 835 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:21,539 INFO] Epoch: 835 | ValAcc: 0.8870 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:21:22,153 INFO] Epoch: 836 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:22,440 INFO] Epoch: 836 | ValAcc: 0.8820 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:21:23,064 INFO] Epoch: 837 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:23,367 INFO] Epoch: 837 | ValAcc: 0.8810 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:21:23,982 INFO] Epoch: 838 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:24,266 INFO] Epoch: 838 | ValAcc: 0.8830 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:21:24,890 INFO] Epoch: 839 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:25,185 INFO] Epoch: 839 | ValAcc: 0.8770 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:21:25,801 INFO] Epoch: 840 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:26,091 INFO] Epoch: 840 | ValAcc: 0.8770 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:21:26,717 INFO] Epoch: 841 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:27,010 INFO] Epoch: 841 | ValAcc: 0.8800 | ValLoss: 0.0426 \n",
      "\n",
      "[2017-12-02 05:21:27,635 INFO] Epoch: 842 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:27,930 INFO] Epoch: 842 | ValAcc: 0.8780 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:21:28,554 INFO] Epoch: 843 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:28,845 INFO] Epoch: 843 | ValAcc: 0.8810 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:21:29,482 INFO] Epoch: 844 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:29,776 INFO] Epoch: 844 | ValAcc: 0.8770 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:21:30,391 INFO] Epoch: 845 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:30,696 INFO] Epoch: 845 | ValAcc: 0.8830 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:21:31,322 INFO] Epoch: 846 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:31,615 INFO] Epoch: 846 | ValAcc: 0.8840 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:21:32,241 INFO] Epoch: 847 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:32,539 INFO] Epoch: 847 | ValAcc: 0.8800 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:21:33,162 INFO] Epoch: 848 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:33,453 INFO] Epoch: 848 | ValAcc: 0.8800 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:21:34,063 INFO] Epoch: 849 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:34,361 INFO] Epoch: 849 | ValAcc: 0.8770 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:21:34,982 INFO] Epoch: 850 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:35,273 INFO] Epoch: 850 | ValAcc: 0.8820 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:21:35,894 INFO] Epoch: 851 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:36,180 INFO] Epoch: 851 | ValAcc: 0.8780 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:21:36,797 INFO] Epoch: 852 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:37,096 INFO] Epoch: 852 | ValAcc: 0.8790 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:21:37,726 INFO] Epoch: 853 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:38,018 INFO] Epoch: 853 | ValAcc: 0.8810 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:21:38,640 INFO] Epoch: 854 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:38,935 INFO] Epoch: 854 | ValAcc: 0.8850 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:21:39,566 INFO] Epoch: 855 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:39,858 INFO] Epoch: 855 | ValAcc: 0.8830 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:21:40,474 INFO] Epoch: 856 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:40,785 INFO] Epoch: 856 | ValAcc: 0.8830 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:21:41,409 INFO] Epoch: 857 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:41,703 INFO] Epoch: 857 | ValAcc: 0.8820 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:21:42,336 INFO] Epoch: 858 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:42,631 INFO] Epoch: 858 | ValAcc: 0.8810 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:21:43,241 INFO] Epoch: 859 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:43,533 INFO] Epoch: 859 | ValAcc: 0.8800 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:21:44,139 INFO] Epoch: 860 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:44,440 INFO] Epoch: 860 | ValAcc: 0.8790 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:21:45,057 INFO] Epoch: 861 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:45,350 INFO] Epoch: 861 | ValAcc: 0.8820 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:21:45,971 INFO] Epoch: 862 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:46,280 INFO] Epoch: 862 | ValAcc: 0.8770 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:21:46,899 INFO] Epoch: 863 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:47,193 INFO] Epoch: 863 | ValAcc: 0.8800 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:21:47,822 INFO] Epoch: 864 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:48,119 INFO] Epoch: 864 | ValAcc: 0.8810 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:21:48,718 INFO] Epoch: 865 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:49,013 INFO] Epoch: 865 | ValAcc: 0.8790 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:21:49,658 INFO] Epoch: 866 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:49,958 INFO] Epoch: 866 | ValAcc: 0.8820 | ValLoss: 0.0426 \n",
      "\n",
      "[2017-12-02 05:21:50,578 INFO] Epoch: 867 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:50,872 INFO] Epoch: 867 | ValAcc: 0.8830 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:21:51,492 INFO] Epoch: 868 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:51,788 INFO] Epoch: 868 | ValAcc: 0.8820 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:21:52,416 INFO] Epoch: 869 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:52,713 INFO] Epoch: 869 | ValAcc: 0.8820 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:21:53,318 INFO] Epoch: 870 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:53,610 INFO] Epoch: 870 | ValAcc: 0.8820 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:21:54,223 INFO] Epoch: 871 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:21:54,513 INFO] Epoch: 871 | ValAcc: 0.8840 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:21:55,116 INFO] Epoch: 872 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:55,408 INFO] Epoch: 872 | ValAcc: 0.8780 | ValLoss: 0.0445 \n",
      "\n",
      "[2017-12-02 05:21:56,034 INFO] Epoch: 873 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:56,325 INFO] Epoch: 873 | ValAcc: 0.8640 | ValLoss: 0.0459 \n",
      "\n",
      "[2017-12-02 05:21:56,944 INFO] Epoch: 874 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:21:57,242 INFO] Epoch: 874 | ValAcc: 0.8730 | ValLoss: 0.0443 \n",
      "\n",
      "[2017-12-02 05:21:57,873 INFO] Epoch: 875 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:21:58,169 INFO] Epoch: 875 | ValAcc: 0.8780 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:21:58,797 INFO] Epoch: 876 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:21:59,092 INFO] Epoch: 876 | ValAcc: 0.8810 | ValLoss: 0.0436 \n",
      "\n",
      "[2017-12-02 05:21:59,716 INFO] Epoch: 877 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:00,008 INFO] Epoch: 877 | ValAcc: 0.8800 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:22:00,622 INFO] Epoch: 878 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:22:00,916 INFO] Epoch: 878 | ValAcc: 0.8760 | ValLoss: 0.0436 \n",
      "\n",
      "[2017-12-02 05:22:01,530 INFO] Epoch: 879 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:01,833 INFO] Epoch: 879 | ValAcc: 0.8750 | ValLoss: 0.0446 \n",
      "\n",
      "[2017-12-02 05:22:02,462 INFO] Epoch: 880 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:02,755 INFO] Epoch: 880 | ValAcc: 0.8770 | ValLoss: 0.0438 \n",
      "\n",
      "[2017-12-02 05:22:03,381 INFO] Epoch: 881 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:03,676 INFO] Epoch: 881 | ValAcc: 0.8820 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:22:04,294 INFO] Epoch: 882 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:04,586 INFO] Epoch: 882 | ValAcc: 0.8770 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:22:05,203 INFO] Epoch: 883 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:05,501 INFO] Epoch: 883 | ValAcc: 0.8840 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:22:06,123 INFO] Epoch: 884 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:06,414 INFO] Epoch: 884 | ValAcc: 0.8830 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:22:07,032 INFO] Epoch: 885 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:07,328 INFO] Epoch: 885 | ValAcc: 0.8790 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:22:07,976 INFO] Epoch: 886 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:08,270 INFO] Epoch: 886 | ValAcc: 0.8810 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:22:08,879 INFO] Epoch: 887 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:09,178 INFO] Epoch: 887 | ValAcc: 0.8860 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:22:09,805 INFO] Epoch: 888 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:10,095 INFO] Epoch: 888 | ValAcc: 0.8820 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:22:10,732 INFO] Epoch: 889 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:11,033 INFO] Epoch: 889 | ValAcc: 0.8840 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:22:11,655 INFO] Epoch: 890 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:11,948 INFO] Epoch: 890 | ValAcc: 0.8820 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:22:12,566 INFO] Epoch: 891 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:12,862 INFO] Epoch: 891 | ValAcc: 0.8810 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:22:13,478 INFO] Epoch: 892 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:13,772 INFO] Epoch: 892 | ValAcc: 0.8810 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:22:14,390 INFO] Epoch: 893 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:14,686 INFO] Epoch: 893 | ValAcc: 0.8790 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:22:15,304 INFO] Epoch: 894 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:15,597 INFO] Epoch: 894 | ValAcc: 0.8830 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:22:16,217 INFO] Epoch: 895 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:16,510 INFO] Epoch: 895 | ValAcc: 0.8790 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:22:17,134 INFO] Epoch: 896 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:17,425 INFO] Epoch: 896 | ValAcc: 0.8800 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:22:18,045 INFO] Epoch: 897 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:18,334 INFO] Epoch: 897 | ValAcc: 0.8810 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:22:18,946 INFO] Epoch: 898 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:19,260 INFO] Epoch: 898 | ValAcc: 0.8810 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:22:19,871 INFO] Epoch: 899 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:20,167 INFO] Epoch: 899 | ValAcc: 0.8800 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:22:20,805 INFO] Epoch: 900 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:21,098 INFO] Epoch: 900 | ValAcc: 0.8780 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:22:21,719 INFO] Epoch: 901 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:22,009 INFO] Epoch: 901 | ValAcc: 0.8790 | ValLoss: 0.0444 \n",
      "\n",
      "[2017-12-02 05:22:22,617 INFO] Epoch: 902 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:22:22,914 INFO] Epoch: 902 | ValAcc: 0.8780 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:22:23,525 INFO] Epoch: 903 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:23,824 INFO] Epoch: 903 | ValAcc: 0.8840 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:22:24,443 INFO] Epoch: 904 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:24,741 INFO] Epoch: 904 | ValAcc: 0.8870 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:22:25,360 INFO] Epoch: 905 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:25,676 INFO] Epoch: 905 | ValAcc: 0.8800 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:22:26,295 INFO] Epoch: 906 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:26,626 INFO] Epoch: 906 | ValAcc: 0.8810 | ValLoss: 0.0436 \n",
      "\n",
      "[2017-12-02 05:22:27,242 INFO] Epoch: 907 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:27,543 INFO] Epoch: 907 | ValAcc: 0.8820 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:22:28,184 INFO] Epoch: 908 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:28,474 INFO] Epoch: 908 | ValAcc: 0.8780 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:22:29,114 INFO] Epoch: 909 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:29,415 INFO] Epoch: 909 | ValAcc: 0.8810 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:22:30,038 INFO] Epoch: 910 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:30,335 INFO] Epoch: 910 | ValAcc: 0.8800 | ValLoss: 0.0436 \n",
      "\n",
      "[2017-12-02 05:22:30,954 INFO] Epoch: 911 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:31,259 INFO] Epoch: 911 | ValAcc: 0.8820 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:22:31,879 INFO] Epoch: 912 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:32,171 INFO] Epoch: 912 | ValAcc: 0.8770 | ValLoss: 0.0438 \n",
      "\n",
      "[2017-12-02 05:22:32,788 INFO] Epoch: 913 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:33,089 INFO] Epoch: 913 | ValAcc: 0.8770 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:22:33,700 INFO] Epoch: 914 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:34,006 INFO] Epoch: 914 | ValAcc: 0.8830 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:22:34,617 INFO] Epoch: 915 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:34,922 INFO] Epoch: 915 | ValAcc: 0.8790 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:22:35,562 INFO] Epoch: 916 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:35,854 INFO] Epoch: 916 | ValAcc: 0.8840 | ValLoss: 0.0428 \n",
      "\n",
      "[2017-12-02 05:22:36,473 INFO] Epoch: 917 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:36,778 INFO] Epoch: 917 | ValAcc: 0.8770 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:22:37,399 INFO] Epoch: 918 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:37,693 INFO] Epoch: 918 | ValAcc: 0.8860 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:22:38,318 INFO] Epoch: 919 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:38,614 INFO] Epoch: 919 | ValAcc: 0.8810 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:22:39,237 INFO] Epoch: 920 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:39,534 INFO] Epoch: 920 | ValAcc: 0.8800 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:22:40,155 INFO] Epoch: 921 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:40,446 INFO] Epoch: 921 | ValAcc: 0.8800 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:22:41,069 INFO] Epoch: 922 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:41,362 INFO] Epoch: 922 | ValAcc: 0.8800 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:22:41,994 INFO] Epoch: 923 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:42,287 INFO] Epoch: 923 | ValAcc: 0.8850 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:22:42,909 INFO] Epoch: 924 | TrainAcc: 1.0000 | TrainLoss: 0.0002\n",
      "[2017-12-02 05:22:43,206 INFO] Epoch: 924 | ValAcc: 0.8730 | ValLoss: 0.0488 \n",
      "\n",
      "[2017-12-02 05:22:43,822 INFO] Epoch: 925 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:44,119 INFO] Epoch: 925 | ValAcc: 0.8740 | ValLoss: 0.0466 \n",
      "\n",
      "[2017-12-02 05:22:44,741 INFO] Epoch: 926 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:45,030 INFO] Epoch: 926 | ValAcc: 0.8810 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:22:45,648 INFO] Epoch: 927 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:45,943 INFO] Epoch: 927 | ValAcc: 0.8760 | ValLoss: 0.0447 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:22:46,556 INFO] Epoch: 928 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:46,856 INFO] Epoch: 928 | ValAcc: 0.8800 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:22:47,474 INFO] Epoch: 929 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:47,775 INFO] Epoch: 929 | ValAcc: 0.8800 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:22:48,406 INFO] Epoch: 930 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:48,696 INFO] Epoch: 930 | ValAcc: 0.8810 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:22:49,328 INFO] Epoch: 931 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:49,622 INFO] Epoch: 931 | ValAcc: 0.8790 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:22:50,226 INFO] Epoch: 932 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:50,521 INFO] Epoch: 932 | ValAcc: 0.8810 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:22:51,136 INFO] Epoch: 933 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:51,434 INFO] Epoch: 933 | ValAcc: 0.8820 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:22:52,058 INFO] Epoch: 934 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:52,351 INFO] Epoch: 934 | ValAcc: 0.8790 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:22:52,973 INFO] Epoch: 935 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:53,266 INFO] Epoch: 935 | ValAcc: 0.8800 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:22:53,884 INFO] Epoch: 936 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:54,183 INFO] Epoch: 936 | ValAcc: 0.8830 | ValLoss: 0.0436 \n",
      "\n",
      "[2017-12-02 05:22:54,804 INFO] Epoch: 937 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:55,097 INFO] Epoch: 937 | ValAcc: 0.8790 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:22:55,720 INFO] Epoch: 938 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:56,009 INFO] Epoch: 938 | ValAcc: 0.8820 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:22:56,612 INFO] Epoch: 939 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:56,912 INFO] Epoch: 939 | ValAcc: 0.8800 | ValLoss: 0.0427 \n",
      "\n",
      "[2017-12-02 05:22:57,523 INFO] Epoch: 940 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:57,812 INFO] Epoch: 940 | ValAcc: 0.8780 | ValLoss: 0.0429 \n",
      "\n",
      "[2017-12-02 05:22:58,429 INFO] Epoch: 941 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:58,724 INFO] Epoch: 941 | ValAcc: 0.8790 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:22:59,348 INFO] Epoch: 942 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:22:59,641 INFO] Epoch: 942 | ValAcc: 0.8860 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:23:00,265 INFO] Epoch: 943 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:00,554 INFO] Epoch: 943 | ValAcc: 0.8810 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:23:01,176 INFO] Epoch: 944 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:01,476 INFO] Epoch: 944 | ValAcc: 0.8760 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:23:02,095 INFO] Epoch: 945 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:02,387 INFO] Epoch: 945 | ValAcc: 0.8810 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:23:03,015 INFO] Epoch: 946 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:03,308 INFO] Epoch: 946 | ValAcc: 0.8810 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:23:03,921 INFO] Epoch: 947 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:04,219 INFO] Epoch: 947 | ValAcc: 0.8810 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:23:04,837 INFO] Epoch: 948 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:05,134 INFO] Epoch: 948 | ValAcc: 0.8830 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:23:05,758 INFO] Epoch: 949 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:06,059 INFO] Epoch: 949 | ValAcc: 0.8850 | ValLoss: 0.0436 \n",
      "\n",
      "[2017-12-02 05:23:06,678 INFO] Epoch: 950 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:06,971 INFO] Epoch: 950 | ValAcc: 0.8840 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:23:07,606 INFO] Epoch: 951 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:07,897 INFO] Epoch: 951 | ValAcc: 0.8790 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:23:08,520 INFO] Epoch: 952 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:08,822 INFO] Epoch: 952 | ValAcc: 0.8790 | ValLoss: 0.0438 \n",
      "\n",
      "[2017-12-02 05:23:09,472 INFO] Epoch: 953 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:09,767 INFO] Epoch: 953 | ValAcc: 0.8800 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:23:10,388 INFO] Epoch: 954 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:10,693 INFO] Epoch: 954 | ValAcc: 0.8800 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:23:11,304 INFO] Epoch: 955 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:11,610 INFO] Epoch: 955 | ValAcc: 0.8810 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:23:12,231 INFO] Epoch: 956 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:12,524 INFO] Epoch: 956 | ValAcc: 0.8830 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:23:13,150 INFO] Epoch: 957 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:13,442 INFO] Epoch: 957 | ValAcc: 0.8800 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:23:14,055 INFO] Epoch: 958 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:14,358 INFO] Epoch: 958 | ValAcc: 0.8790 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:23:14,971 INFO] Epoch: 959 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:15,277 INFO] Epoch: 959 | ValAcc: 0.8810 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:23:15,888 INFO] Epoch: 960 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:16,188 INFO] Epoch: 960 | ValAcc: 0.8820 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:23:16,804 INFO] Epoch: 961 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:17,092 INFO] Epoch: 961 | ValAcc: 0.8820 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:23:17,701 INFO] Epoch: 962 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:18,006 INFO] Epoch: 962 | ValAcc: 0.8810 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:23:18,654 INFO] Epoch: 963 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:18,945 INFO] Epoch: 963 | ValAcc: 0.8840 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:23:19,591 INFO] Epoch: 964 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:19,906 INFO] Epoch: 964 | ValAcc: 0.8830 | ValLoss: 0.0430 \n",
      "\n",
      "[2017-12-02 05:23:20,520 INFO] Epoch: 965 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:20,814 INFO] Epoch: 965 | ValAcc: 0.8800 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:23:21,445 INFO] Epoch: 966 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:21,743 INFO] Epoch: 966 | ValAcc: 0.8830 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:23:22,354 INFO] Epoch: 967 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:22,647 INFO] Epoch: 967 | ValAcc: 0.8840 | ValLoss: 0.0438 \n",
      "\n",
      "[2017-12-02 05:23:23,271 INFO] Epoch: 968 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:23,565 INFO] Epoch: 968 | ValAcc: 0.8780 | ValLoss: 0.0438 \n",
      "\n",
      "[2017-12-02 05:23:24,186 INFO] Epoch: 969 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:24,487 INFO] Epoch: 969 | ValAcc: 0.8850 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:23:25,099 INFO] Epoch: 970 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:25,390 INFO] Epoch: 970 | ValAcc: 0.8830 | ValLoss: 0.0438 \n",
      "\n",
      "[2017-12-02 05:23:25,997 INFO] Epoch: 971 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:26,291 INFO] Epoch: 971 | ValAcc: 0.8810 | ValLoss: 0.0442 \n",
      "\n",
      "[2017-12-02 05:23:26,900 INFO] Epoch: 972 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:27,191 INFO] Epoch: 972 | ValAcc: 0.8770 | ValLoss: 0.0440 \n",
      "\n",
      "[2017-12-02 05:23:27,803 INFO] Epoch: 973 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:28,092 INFO] Epoch: 973 | ValAcc: 0.8830 | ValLoss: 0.0438 \n",
      "\n",
      "[2017-12-02 05:23:28,713 INFO] Epoch: 974 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:29,007 INFO] Epoch: 974 | ValAcc: 0.8820 | ValLoss: 0.0436 \n",
      "\n",
      "[2017-12-02 05:23:29,644 INFO] Epoch: 975 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:29,935 INFO] Epoch: 975 | ValAcc: 0.8750 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:23:30,558 INFO] Epoch: 976 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:30,861 INFO] Epoch: 976 | ValAcc: 0.8750 | ValLoss: 0.0442 \n",
      "\n",
      "[2017-12-02 05:23:31,487 INFO] Epoch: 977 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:31,782 INFO] Epoch: 977 | ValAcc: 0.8800 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:23:32,404 INFO] Epoch: 978 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:32,701 INFO] Epoch: 978 | ValAcc: 0.8830 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:23:33,315 INFO] Epoch: 979 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-02 05:23:33,610 INFO] Epoch: 979 | ValAcc: 0.8820 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:23:34,247 INFO] Epoch: 980 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:34,540 INFO] Epoch: 980 | ValAcc: 0.8840 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:23:35,142 INFO] Epoch: 981 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:35,440 INFO] Epoch: 981 | ValAcc: 0.8830 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:23:36,062 INFO] Epoch: 982 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:36,360 INFO] Epoch: 982 | ValAcc: 0.8830 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:23:36,981 INFO] Epoch: 983 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:37,270 INFO] Epoch: 983 | ValAcc: 0.8830 | ValLoss: 0.0439 \n",
      "\n",
      "[2017-12-02 05:23:37,898 INFO] Epoch: 984 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:38,190 INFO] Epoch: 984 | ValAcc: 0.8810 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:23:38,824 INFO] Epoch: 985 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:39,117 INFO] Epoch: 985 | ValAcc: 0.8790 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:23:39,740 INFO] Epoch: 986 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:40,042 INFO] Epoch: 986 | ValAcc: 0.8810 | ValLoss: 0.0431 \n",
      "\n",
      "[2017-12-02 05:23:40,647 INFO] Epoch: 987 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:40,937 INFO] Epoch: 987 | ValAcc: 0.8790 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:23:41,552 INFO] Epoch: 988 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:41,846 INFO] Epoch: 988 | ValAcc: 0.8750 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:23:42,456 INFO] Epoch: 989 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:42,749 INFO] Epoch: 989 | ValAcc: 0.8800 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:23:43,371 INFO] Epoch: 990 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:43,667 INFO] Epoch: 990 | ValAcc: 0.8780 | ValLoss: 0.0439 \n",
      "\n",
      "[2017-12-02 05:23:44,285 INFO] Epoch: 991 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:44,582 INFO] Epoch: 991 | ValAcc: 0.8830 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:23:45,205 INFO] Epoch: 992 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:45,494 INFO] Epoch: 992 | ValAcc: 0.8800 | ValLoss: 0.0436 \n",
      "\n",
      "[2017-12-02 05:23:46,108 INFO] Epoch: 993 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:46,402 INFO] Epoch: 993 | ValAcc: 0.8810 | ValLoss: 0.0436 \n",
      "\n",
      "[2017-12-02 05:23:47,013 INFO] Epoch: 994 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:47,312 INFO] Epoch: 994 | ValAcc: 0.8820 | ValLoss: 0.0435 \n",
      "\n",
      "[2017-12-02 05:23:47,933 INFO] Epoch: 995 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:48,227 INFO] Epoch: 995 | ValAcc: 0.8840 | ValLoss: 0.0433 \n",
      "\n",
      "[2017-12-02 05:23:48,842 INFO] Epoch: 996 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:49,151 INFO] Epoch: 996 | ValAcc: 0.8840 | ValLoss: 0.0432 \n",
      "\n",
      "[2017-12-02 05:23:49,788 INFO] Epoch: 997 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:50,085 INFO] Epoch: 997 | ValAcc: 0.8810 | ValLoss: 0.0434 \n",
      "\n",
      "[2017-12-02 05:23:50,726 INFO] Epoch: 998 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:51,023 INFO] Epoch: 998 | ValAcc: 0.8830 | ValLoss: 0.0437 \n",
      "\n",
      "[2017-12-02 05:23:51,782 INFO] Epoch: 999 | TrainAcc: 1.0000 | TrainLoss: 0.0001\n",
      "[2017-12-02 05:23:52,082 INFO] Epoch: 999 | ValAcc: 0.8780 | ValLoss: 0.0443 \n",
      "\n",
      "[2017-12-02 05:23:52,095 INFO] Train done.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwYAAAIqCAYAAACe310tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1d4b7898>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 387
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwYAAAIqCAYAAACe310tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiIiIgICgxERERERAQFBiIiIiIiAvx/x/UCjHlhkPkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1969bc18>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 387
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Net()\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "\n",
    "def save_checkpoint(state, filename='./save/checkpoint_{}.pth'.format(ex_name)):\n",
    "    torch.save(state, filename)\n",
    "    #shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "    \n",
    "criterion = nn.KLDivLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "tracker = TrainingTracker()\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    tracker.epoch = epoch\n",
    "    \n",
    "    _train(model, train_loader, criterion, optimizer, tracker)\n",
    "    _validate(model, val_loader, criterion, tracker)\n",
    "    \n",
    "    # if latest accuracy is the best in history\n",
    "    if np.argmax(tracker.history['val_acc']) == len(tracker.history['val_acc']) - 1:\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        })\n",
    "    \n",
    "logger.info('Train done.')\n",
    "tracker.plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Pseudo Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [00:14<00:00, 18.98it/s]\n",
      "[2017-12-02 14:19:45,805 INFO] TestAcc: 0.8919 |TestLoss: 0.0392 \n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "resume = torch.load('./save/checkpoint_{}.pth'.format(ex_name))\n",
    "model.load_state_dict(resume['state_dict'])\n",
    "_test(model, test_loader, criterion, make_pl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
